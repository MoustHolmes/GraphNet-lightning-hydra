{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import pytorch_lightning as pl\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables within the SQL database is:\n",
      "                  name\n",
      "0                retro\n",
      "1     SplitInIcePulses\n",
      "2  I3MCTree__primaries\n",
      "3  I3MCTree__particles\n",
      "4   I3TriggerHierarchy\n",
      "5                truth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mini_db_path = \"/groups/icecube/moust/storage/140021_db/db_out_mini/merged_140021_mini.db\"\n",
    "query_all =\"SELECT * FROM truth\"\n",
    "with sqlite3.connect(mini_db_path) as conn:\n",
    "    db_tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type = 'table'\", conn)\n",
    "    print('Tables within the SQL database is:')\n",
    "    print(db_tables)\n",
    "    print()\n",
    "    mini_db = {name:  pd.read_sql_query(\"SELECT * FROM \"+name, conn) for name in db_tables.name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "  (xx, y) = zip(*batch)\n",
    "  x_lens = [len(x) for x in xx]\n",
    "  xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
    "\n",
    "  pad_mask = torch.zeros_like(xx_pad[:, :, 0]).type(torch.bool)\n",
    "  for i, length in enumerate(x_lens):\n",
    "    pad_mask[i, length:] = True\n",
    "\n",
    "  return xx_pad, torch.tensor(y), pad_mask\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "  def __init__(self, \n",
    "               db_path: str, \n",
    "               event_no_list: List[int], #event_no_list_path: str,\n",
    "               pulsemap: str,\n",
    "               input_cols: List[str],\n",
    "               target_cols: List[str],\n",
    "               truth_table: str = \"truth\"\n",
    "               ):\n",
    "    self.db_path = db_path\n",
    "    self.event_no_list = event_no_list #self.event_no_list_path = event_no_list_path\n",
    "    self.pulsemap = pulsemap\n",
    "    self.input_cols = input_cols\n",
    "    self.target_cols = target_cols\n",
    "    self.truth_table = truth_table\n",
    "\n",
    "\n",
    "    if isinstance(list(input_cols), list):\n",
    "      self.input_cols_str = \", \".join(input_cols)\n",
    "    else:\n",
    "\n",
    "      self.input_cols_str = input_cols\n",
    "\n",
    "    if isinstance(target_cols, list):\n",
    "      self.target_cols_str = \", \".join(target_cols)\n",
    "    else:\n",
    "      self.target_cols_str = target_cols\n",
    "    \n",
    "    # self.event_no_list = np.genfromtxt(self.event_no_list_path,dtype=int)\n",
    "\n",
    "    self.data_len = len(self.event_no_list)\n",
    "    \n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    event_no = self.event_no_list[index]\n",
    "    with sqlite3.connect(self.db_path) as conn:\n",
    "      features = Tensor(conn.execute(f\"SELECT {self.input_cols_str} FROM {self.pulsemap} WHERE event_no == {event_no}\").fetchall())\n",
    "      truth = Tensor(conn.execute(f\"SELECT {self.target_cols_str} FROM {self.truth_table} WHERE event_no == {event_no}\").fetchall())\n",
    "    return features, truth\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpledataset = SimpleDataset( \n",
    "               db_path = mini_db_path, \n",
    "               event_no_list = np.arange(10),\n",
    "               pulsemap = \"SplitInIcePulses\",\n",
    "               input_cols = [\"charge\",\"dom_time\",\"dom_x\",\"dom_y\",\"dom_z\"],\n",
    "               target_cols = [\"energy\",\"inelasticity\"],\n",
    "               )\n",
    "dataloader = DataLoader(dataset=simpledataset, batch_size = 4, collate_fn = pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dataiter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(dataloader)\n\u001b[0;32m----> 2\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(dataiter)\n\u001b[1;32m      3\u001b[0m x1, truth , lengths\u001b[39m=\u001b[39m data\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(x1\u001b[39m.\u001b[39mshape, truth, lengths)\n",
      "File \u001b[0;32m~/miniconda3/envs/icet2/lib/python3.8/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/icet2/lib/python3.8/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/icet2/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m, in \u001b[0;36mpad_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i, length \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(x_lens):\n\u001b[1;32m      8\u001b[0m   pad_mask[i, length:] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mreturn\u001b[39;00m xx_pad, torch\u001b[39m.\u001b[39;49mtensor(y), pad_mask\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "dataiter = iter(dataloader)\n",
    "data = next(dataiter)\n",
    "x1, truth , lengths= data\n",
    "print(x1.shape, truth, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m i, (features, truth,pad) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(truth\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(features\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/icet2/lib/python3.8/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/icet2/lib/python3.8/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/icet2/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m, in \u001b[0;36mpad_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i, length \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(x_lens):\n\u001b[1;32m      8\u001b[0m   pad_mask[i, length:] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mreturn\u001b[39;00m xx_pad, torch\u001b[39m.\u001b[39;49mtensor(y), pad_mask\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "for i, (features, truth,pad) in enumerate(dataloader):\n",
    "    print(truth.shape)\n",
    "    print(features.shape)\n",
    "    print(pad.shape)\n",
    "    # pred = model(features)\n",
    "    # print(pred.shape)\n",
    "    if i == 1:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "798460b207845be22dae3ef8b3ec85337a437d29716aaad41977fc3150de5ddb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
