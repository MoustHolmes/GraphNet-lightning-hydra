{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/icecube/moust/miniconda3/envs/icet2/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_hip.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/groups/icecube/moust/miniconda3/envs/icet2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "import math\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from timm.models.layers import drop_path, trunc_normal_\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset, Sampler, SequentialSampler #random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "# from torch_geometric.utils import to_dense_batch\n",
    "# from torch_geometric.nn.pool import knn_graph\n",
    "# from torch_geometric.typing import Adj\n",
    "# from torch_scatter import scatter_max, scatter_mean, scatter_min, scatter_sum\n",
    "from typing import Any, Callable, List, Dict, Optional, Sequence, Tuple, Union, Iterator\n",
    "from torch import Tensor, LongTensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset, batch_sampler, collate_fn and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dom_types_and_rde_one_hot( dom_type, rde):\n",
    "        # pDom dom with low efficiency\n",
    "        pdom_low_qe = ((dom_type == 20) & (rde == 1)).float().unsqueeze(-1)\n",
    "        # pDOM dom with high efficiency\n",
    "        pdom_high_qe = ((dom_type == 20) & (rde == 1.35)).float().unsqueeze(-1)\n",
    "        # pDOM upgrade == 110\n",
    "        pdom_upgrade = (dom_type == 110).float().unsqueeze(-1)\n",
    "        # D-EGG == 120\n",
    "        d_egg = (dom_type == 120).float().unsqueeze(-1)\n",
    "        # mDOM == 130\n",
    "        mdom = (dom_type == 130).float().unsqueeze(-1)\n",
    "\n",
    "        return torch.cat([pdom_low_qe, pdom_high_qe, pdom_upgrade, d_egg, mdom], dim=-1)\n",
    "\n",
    "def combine_dom_types_and_rde(dom_type, rde):\n",
    "    # pDom dom with low efficiency\n",
    "    pdom_low_qe = ((dom_type == 20) & (rde == 1)).long() * 0\n",
    "    # pDOM dom with high efficiency\n",
    "    pdom_high_qe = ((dom_type == 20) & (rde == 1.35)).long() * 1\n",
    "    # pDOM upgrade == 110\n",
    "    pdom_upgrade = (dom_type == 110).long() * 2\n",
    "    # D-EGG == 120\n",
    "    d_egg = (dom_type == 120).long() * 3\n",
    "    # mDOM == 130\n",
    "    mdom = (dom_type == 130).long() * 4\n",
    "\n",
    "    return pdom_low_qe + pdom_high_qe + pdom_upgrade + d_egg + mdom\n",
    "\n",
    "class ChunkDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch dataset for loading chunked data from an SQLite database.\n",
    "    This dataset retrieves pulsemap and truth data for each event from the database.\n",
    "\n",
    "    Args:\n",
    "        db_filename (str): Filename of the SQLite database.\n",
    "        csv_filenames (list of str): List of CSV filenames containing event numbers.\n",
    "        pulsemap_table (str): Name of the table containing pulsemap data.\n",
    "        truth_table (str): Name of the table containing truth data.\n",
    "        truth_variable (str): Name of the variable to query from the truth table.\n",
    "        feature_variables (list of str): List of variable names to query from the pulsemap table.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        db_path: str,\n",
    "        chunk_csvs: List[str],\n",
    "        pulsemap: str,\n",
    "        truth_table: str,\n",
    "        target_cols: str,\n",
    "        input_cols: List[str]\n",
    "    ) -> None:\n",
    "        self.conn = sqlite3.connect(db_path)  # Connect to the SQLite database\n",
    "        self.c = self.conn.cursor()\n",
    "        self.event_nos = []\n",
    "        for csv_filename in chunk_csvs:\n",
    "            df = pd.read_csv(csv_filename)\n",
    "            self.event_nos.extend(df['event_no'].tolist())  # Collect event numbers from CSV files\n",
    "        self.pulsemap = pulsemap  # Name of the table containing pulsemap data\n",
    "        self.truth_table = truth_table  # Name of the table containing truth data\n",
    "        self.target_cols = target_cols  # Name of the variable to query from the truth table\n",
    "        self.input_cols = input_cols  # List of variable names to query from the pulsemap table\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.event_nos)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        event_no = idx # self.event_nos[idx]\n",
    "\n",
    "        # Query the truth variable for the given event number\n",
    "        self.c.execute(f\"SELECT {self.target_cols} FROM {self.truth_table} WHERE event_no = ?\", (event_no,))\n",
    "        truth_value = self.c.fetchone()[0]\n",
    "        \n",
    "\n",
    "        pos_cols = ['dom_x', 'dom_y', 'dom_z']\n",
    "\n",
    "        rde_index = self.input_cols.index('rde')\n",
    "        dom_type_index = self.input_cols.index('dom_type')\n",
    "        pos_indices = [self.input_cols.index(col) for col in pos_cols]\n",
    "        rest_indices = [i for i in range(len(self.input_cols)) if i not in [rde_index, dom_type_index] + pos_indices]\n",
    "\n",
    "        input_query = ', '.join(self.input_cols)\n",
    "        # Query the feature variables from the pulsemap table for the given event number\n",
    "        self.c.execute(f\"SELECT {input_query} FROM {self.pulsemap} WHERE event_no = ?\", (event_no,))\n",
    "        pulsemap_data_rows = self.c.fetchall()\n",
    "    \n",
    "        # Convert pulsemap_data_rows into a dictionary of tensors\n",
    "        \n",
    "        pulsemap_data = {self.input_cols[i]: torch.tensor( [row[i] for row in pulsemap_data_rows], dtype=torch.float32)\n",
    "                        for i in rest_indices}\n",
    "        \n",
    "        # Get the necessary data for combined_dom_type and pos\n",
    "        dom_type_data = [row[dom_type_index] for row in pulsemap_data_rows] #[row[i] for row in pulsemap_data_rows for i in combined_dom_type_indices]\n",
    "        rde_data = [row[rde_index] for row in pulsemap_data_rows]\n",
    "        pos_data = [[row[i] for row in pulsemap_data_rows] for i in pos_indices]\n",
    "\n",
    "        pulsemap_data[\"combined_dom_type\"] = combine_dom_types_and_rde(torch.tensor(dom_type_data, dtype=torch.float32),\n",
    "                                                                    torch.tensor(rde_data, dtype=torch.float32))\n",
    "        pulsemap_data[\"pos\"] = torch.stack([torch.tensor(col_data, dtype=torch.float32) for col_data in pos_data], dim=1)\n",
    "        pulsemap_data[\"L0\"] = torch.tensor(len(pulsemap_data_rows), dtype=torch.int32)\n",
    "        return pulsemap_data, torch.tensor(truth_value, dtype=torch.float32)\n",
    "    \n",
    "\n",
    "\n",
    "class ChunkSampler(Sampler):\n",
    "    \"\"\"\n",
    "    PyTorch sampler for creating chunks from event numbers.\n",
    "\n",
    "    Args:\n",
    "        csv_filenames (List[str]): List of CSV filenames containing event numbers.\n",
    "        batch_sizes (List[int]): List of batch sizes for each CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        chunk_csvs: List[str], \n",
    "        batch_sizes: List[int]\n",
    "    ) -> None:\n",
    "        self.event_nos = []\n",
    "        for csv_filename, batch_size in zip(chunk_csvs, batch_sizes):\n",
    "            event_nos = pd.read_csv(csv_filename)['event_no'].tolist()\n",
    "            self.event_nos.extend([event_nos[i:i + batch_size] for i in range(0, len(event_nos), batch_size)])\n",
    "\n",
    "    def __iter__(self) -> Iterator:\n",
    "        return iter(self.event_nos)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.event_nos)\n",
    "    \n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    This collate function is specifically designed for the dataset that\n",
    "    returns a dictionary of tensors. It will pad the sequences to the same\n",
    "    length and concatenate along the batch dimension given a list of such \n",
    "    dictionaries (i.e., a batch).\n",
    "    \"\"\"\n",
    "    batch_keys = batch[0][0].keys()\n",
    "    collated_batch = {}\n",
    "\n",
    "    max_len = max(max(item[0][key].size(0) for item in batch) for key in batch_keys if key != 'L0')\n",
    "\n",
    "    for key in batch_keys:\n",
    "        if key != 'L0':\n",
    "            # Pad the sequences to the same length and stack along a new batch dimension\n",
    "            collated_batch[key] = torch.stack([torch.cat([item[0][key], item[0][key].new_zeros(max_len - item[0][key].size(0), item[0][key].size(1)) if len(item[0][key].shape) > 1 else item[0][key].new_zeros(max_len - item[0][key].size(0))]) for item in batch])\n",
    "        else:\n",
    "            # If the key is 'L0', simply collect the values into a list\n",
    "            collated_batch[key] = torch.tensor([item[0][key] for item in batch])\n",
    "\n",
    "    # Create a mask that indicates where the original sequence ends and the padding begins\n",
    "    collated_batch['mask'] = collated_batch['L0'].new_ones((len(batch), max_len)).bool()\n",
    "    for i, l0 in enumerate(collated_batch['L0']):\n",
    "        collated_batch['mask'][i, l0:] = False\n",
    "    # Stack all target tensors along a new batch dimension\n",
    "    targets = torch.stack([item[1] for item in batch])\n",
    "    \n",
    "    return collated_batch, targets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset test\n",
      "\n",
      "0\n",
      "tensor(0, dtype=torch.int32)\n",
      "1\n",
      "tensor(0, dtype=torch.int32)\n",
      "2\n",
      "tensor(0, dtype=torch.int32)\n",
      "tensor(24, dtype=torch.int32)\n",
      "\n",
      "DataLoader test\n",
      "\n",
      "0\n",
      "torch.Size([256])\n",
      "torch.Size([256, 9, 3])\n",
      "1\n",
      "torch.Size([256])\n",
      "torch.Size([256, 9, 3])\n",
      "2\n",
      "torch.Size([256])\n",
      "torch.Size([256, 9, 3])\n"
     ]
    }
   ],
   "source": [
    "chunk_csv_train = [\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_1.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_2.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_3.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_4.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_5.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_6.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_7.csv\",\n",
    "]\n",
    "chunk_csv_test = [\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_1.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_2.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_3.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_4.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_5.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_6.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_7.csv\",\n",
    "]\n",
    "chunk_csv_val = [\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_1.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_2.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_3.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_4.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_5.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_6.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_7.csv\",\n",
    "]\n",
    "batch_sizes = [512, 256, 128, 64, 32, 16, 8]\n",
    "truth_table = \"truth\"\n",
    "db_path = \"/groups/icecube/petersen/GraphNetDatabaseRepository/Upgrade_Data/sqlite3/dev_step4_upgrade_028_with_noise_dynedge_pulsemap_v3_merger_aftercrash.db\"\n",
    "pulsemap = \"SplitInIcePulses_dynedge_v2_Pulses\"\n",
    "input_cols =  [\"dom_x\", \"dom_y\", \"dom_z\", \"dom_time\", \"charge\", \"rde\", \"dom_type\"]\n",
    "target_cols = \"inelasticity\"\n",
    "\n",
    "print()\n",
    "print(\"Dataset test\")\n",
    "print()\n",
    "\n",
    "dataset = ChunkDataset(\n",
    "    db_path=db_path, \n",
    "    chunk_csvs=chunk_csv_train, \n",
    "    pulsemap=pulsemap, \n",
    "    truth_table=truth_table, \n",
    "    target_cols=target_cols, \n",
    "    input_cols=input_cols\n",
    "    )\n",
    "for i, (features, truth) in enumerate(dataset):\n",
    "    print(i)\n",
    "    # print(features, truth)\n",
    "    print(features['L0'])\n",
    "    if i >= 2:\n",
    "        break\n",
    "features, truth = dataset[6]\n",
    "\n",
    "    # print(features, truth)\n",
    "print(features['L0'])\n",
    "\n",
    "dl = DataLoader(\n",
    "    dataset=dataset,\n",
    "    collate_fn=collate_fn,\n",
    "    batch_sampler=ChunkSampler(chunk_csv_train, batch_sizes),\n",
    "    num_workers=0,\n",
    "    )\n",
    "print()\n",
    "print(\"DataLoader test\")\n",
    "print()\n",
    "for i, (features, truth) in enumerate(dl):\n",
    "    print(i)\n",
    "    print(features['L0'].shape)\n",
    "    print(features['pos'].shape)\n",
    "    # print(features['L0'][0].item())\n",
    "    # print(features['L0'].max(), features['L0'].min())\n",
    "\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropPath(nn.Module):\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return \"p={}\".format(self.drop_prob)\n",
    "\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        hidden_features=None,\n",
    "        out_features=None,\n",
    "        act_layer=nn.GELU,\n",
    "        drop=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        # x = self.drop(x)\n",
    "        # commit this for the orignal BERT implement\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# BEiTv2 block\n",
    "class Block(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads,\n",
    "        mlp_ratio=4.0,\n",
    "        qkv_bias=False,\n",
    "        qk_scale=None,\n",
    "        drop=0.0,\n",
    "        attn_drop=0.0,\n",
    "        drop_path=0.0,\n",
    "        init_values=None,\n",
    "        act_layer=nn.GELU,\n",
    "        norm_layer=nn.LayerNorm,\n",
    "        window_size=None,\n",
    "        attn_head_dim=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            dim, num_heads, dropout=drop, batch_first=True,\n",
    "        )\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(\n",
    "            in_features=dim,\n",
    "            hidden_features=mlp_hidden_dim,\n",
    "            act_layer=act_layer,\n",
    "            drop=drop,\n",
    "        )\n",
    "\n",
    "        if init_values is not None:\n",
    "            self.gamma_1 = nn.Parameter(\n",
    "                init_values * torch.ones((dim)), requires_grad=True\n",
    "            )\n",
    "            self.gamma_2 = nn.Parameter(\n",
    "                init_values * torch.ones((dim)), requires_grad=True\n",
    "            )\n",
    "        else:\n",
    "            self.gamma_1, self.gamma_2 = None, None\n",
    "\n",
    "    def forward(self, x, attn_mask=None, key_padding_mask=None):\n",
    "        if self.gamma_1 is None:\n",
    "            xn = self.norm1(x)\n",
    "            x_attn, attn_weights = self.attn(\n",
    "                    xn,\n",
    "                    xn,\n",
    "                    xn,\n",
    "                    attn_mask=attn_mask,\n",
    "                    key_padding_mask=key_padding_mask,\n",
    "                    need_weights=True,\n",
    "                    average_attn_weights=False\n",
    "                )\n",
    "            x = x + self.drop_path(x_attn)\n",
    "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        else:\n",
    "            xn = self.norm1(x)\n",
    "            x_attn, attn_weights = self.attn(\n",
    "                    xn,\n",
    "                    xn,\n",
    "                    xn,\n",
    "                    attn_mask=attn_mask,\n",
    "                    key_padding_mask=key_padding_mask,\n",
    "                    need_weights=True,\n",
    "                    average_attn_weights=False\n",
    "                )\n",
    "            x = x + self.drop_path(x_attn)\n",
    "            x = x + self.drop_path(self.gamma_2 * self.mlp(self.norm2(x)))\n",
    "\n",
    "        return x, attn_weights\n",
    "\n",
    "\n",
    "class Attention_rel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads=8,\n",
    "        qkv_bias=False,\n",
    "        qk_scale=None,\n",
    "        attn_drop=0.0,\n",
    "        proj_drop=0.0,\n",
    "        attn_head_dim=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        if attn_head_dim is not None:\n",
    "            head_dim = attn_head_dim\n",
    "        all_head_dim = head_dim * self.num_heads\n",
    "        self.scale = qk_scale or head_dim**-0.5\n",
    "\n",
    "        self.proj_q = nn.Linear(dim, all_head_dim, bias=False)\n",
    "        self.proj_k = nn.Linear(dim, all_head_dim, bias=False)\n",
    "        self.proj_v = nn.Linear(dim, all_head_dim, bias=False)\n",
    "        if qkv_bias:\n",
    "            self.q_bias = nn.Parameter(torch.zeros(all_head_dim))\n",
    "            self.v_bias = nn.Parameter(torch.zeros(all_head_dim))\n",
    "        else:\n",
    "            self.q_bias = None\n",
    "            self.v_bias = None\n",
    "\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(all_head_dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, q, k, v, rel_pos_bias=None, key_padding_mask=None):\n",
    "        # rel_pos_bias: B L L C/h\n",
    "        # key_padding_mask - float with -inf\n",
    "        B, N, C = q.shape\n",
    "        # qkv_bias = None\n",
    "        # if self.q_bias is not None:\n",
    "        #    qkv_bias = torch.cat((self.q_bias, torch.zeros_like(self.v_bias, requires_grad=False), self.v_bias))\n",
    "        # qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        # qkv = F.linear(input=x, weight=self.qkv.weight, bias=qkv_bias)\n",
    "        # qkv = qkv.reshape(B, N, 3, self.num_heads, -1).permute(2, 0, 3, 1, 4)\n",
    "        # q, k, v = qkv[0], qkv[1], qkv[2]   # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        q = F.linear(input=q, weight=self.proj_q.weight, bias=self.q_bias)\n",
    "        q = q.reshape(B, N, self.num_heads, -1).permute(0, 2, 1, 3)\n",
    "        k = F.linear(input=k, weight=self.proj_k.weight, bias=None)\n",
    "        k = k.reshape(B, k.shape[1], self.num_heads, -1).permute(0, 2, 1, 3)\n",
    "        v = F.linear(input=v, weight=self.proj_v.weight, bias=self.v_bias)\n",
    "        v = v.reshape(B, v.shape[1], self.num_heads, -1).permute(0, 2, 1, 3)\n",
    "        q = q * self.scale\n",
    "        attn = q @ k.transpose(-2, -1)\n",
    "\n",
    "        if rel_pos_bias is not None:\n",
    "            bias = torch.einsum(\"bhic,bijc->bhij\", q, rel_pos_bias).type_as(attn)\n",
    "            attn = attn + bias\n",
    "        if key_padding_mask is not None:\n",
    "            assert (\n",
    "                key_padding_mask.dtype == torch.float32\n",
    "                or key_padding_mask.dtype == torch.float16\n",
    "            ), \"incorrect mask dtype\"\n",
    "            bias = torch.min(key_padding_mask[:, None, :], key_padding_mask[:, :, None]).type_as(attn)\n",
    "            bias[\n",
    "                torch.max(key_padding_mask[:, None, :], key_padding_mask[:, :, None])\n",
    "                < 0\n",
    "            ] = 0\n",
    "            attn = attn + bias.unsqueeze(1)\n",
    "\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2)\n",
    "        if rel_pos_bias is not None:\n",
    "            x = x + torch.einsum(\"bhij,bijc->bihc\", attn, rel_pos_bias)\n",
    "        x = x.reshape(B, N, -1)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "\n",
    "        return x, attn\n",
    "\n",
    "\n",
    "# BEiTv2 block\n",
    "class Block_rel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads,\n",
    "        mlp_ratio=4.0,\n",
    "        qkv_bias=False,\n",
    "        qk_scale=None,\n",
    "        drop=0.0,\n",
    "        attn_drop=0.0,\n",
    "        drop_path=0.0,\n",
    "        init_values=None,\n",
    "        act_layer=nn.GELU,\n",
    "        norm_layer=nn.LayerNorm,\n",
    "        window_size=None,\n",
    "        attn_head_dim=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = Attention_rel(\n",
    "            dim, num_heads, attn_drop=attn_drop, qkv_bias=qkv_bias\n",
    "        )\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(\n",
    "            in_features=dim,\n",
    "            hidden_features=mlp_hidden_dim,\n",
    "            act_layer=act_layer,\n",
    "            drop=drop,\n",
    "        )\n",
    "\n",
    "        if init_values is not None:\n",
    "            self.gamma_1 = nn.Parameter(\n",
    "                init_values * torch.ones((dim)), requires_grad=True\n",
    "            )\n",
    "            self.gamma_2 = nn.Parameter(\n",
    "                init_values * torch.ones((dim)), requires_grad=True\n",
    "            )\n",
    "        else:\n",
    "            self.gamma_1, self.gamma_2 = None, None\n",
    "\n",
    "    def forward(self, x, key_padding_mask=None, rel_pos_bias=None, kv=None):\n",
    "        if self.gamma_1 is None:\n",
    "            xn = self.norm1(x)\n",
    "            kv = xn if kv is None else self.norm1(kv)\n",
    "            x_attn, attn_weights = self.attn(\n",
    "                    xn,\n",
    "                    kv,\n",
    "                    kv,\n",
    "                    rel_pos_bias=rel_pos_bias,\n",
    "                    key_padding_mask=key_padding_mask,\n",
    "                )\n",
    "            x = x + self.drop_path(x_attn)\n",
    "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        else:\n",
    "            xn = self.norm1(x)\n",
    "            kv = xn if kv is None else self.norm1(kv)\n",
    "            x_attn, attn_weights =self.attn(\n",
    "                        xn,\n",
    "                        kv,\n",
    "                        kv,\n",
    "                        rel_pos_bias=rel_pos_bias,\n",
    "                        key_padding_mask=key_padding_mask,\n",
    "                    )\n",
    "            x = x + self.drop_path( self.gamma_1 * self.drop_path(x_attn))\n",
    "            x = x + self.drop_path(self.gamma_2 * self.mlp(self.norm2(x)))\n",
    "        return x, attn_weights\n",
    "\n",
    "\n",
    "class LocalBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim=192,\n",
    "        num_heads=192 // 64,\n",
    "        mlp_ratio=4,\n",
    "        drop_path=0,\n",
    "        init_values=1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.proj_rel_bias = nn.Linear(dim // num_heads, dim // num_heads)\n",
    "        self.block = Block_rel(\n",
    "            dim=dim,\n",
    "            num_heads=num_heads,\n",
    "            mlp_ratio=mlp_ratio,\n",
    "            drop_path=drop_path,\n",
    "            init_values=init_values,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, nbs, key_padding_mask=None, rel_pos_bias=None):\n",
    "        B, Lmax, C = x.shape\n",
    "        mask = (\n",
    "            key_padding_mask\n",
    "            if not (key_padding_mask is None)\n",
    "            else torch.ones(B, Lmax, dtype=torch.bool)\n",
    "        )\n",
    "\n",
    "        m = torch.gather(mask.unsqueeze(1).expand(-1, Lmax, -1), 2, nbs)\n",
    "        attn_mask = torch.zeros(m.shape)\n",
    "        attn_mask[~mask] = -torch.inf\n",
    "        attn_mask = attn_mask[mask]\n",
    "\n",
    "        if rel_pos_bias is not None:\n",
    "            rel_pos_bias = torch.gather(\n",
    "                rel_pos_bias,\n",
    "                2,\n",
    "                nbs.unsqueeze(-1).expand(-1, -1, -1, rel_pos_bias.shape[-1]),\n",
    "            )\n",
    "            rel_pos_bias = rel_pos_bias[mask]\n",
    "            rel_pos_bias = self.proj_rel_bias(rel_pos_bias).unsqueeze(1)\n",
    "\n",
    "        xl = torch.gather(\n",
    "            x.unsqueeze(1).expand(-1, Lmax, -1, -1),\n",
    "            2,\n",
    "            nbs.unsqueeze(-1).expand(-1, -1, -1, C),\n",
    "        )\n",
    "        xl = xl[mask]\n",
    "        # modify only the node (0th element)\n",
    "        xl = self.block(\n",
    "            xl[:, :1],\n",
    "            rel_pos_bias=rel_pos_bias,\n",
    "            key_padding_mask=attn_mask[:, :1],\n",
    "            kv=xl,\n",
    "        )\n",
    "        x = torch.zeros(x.shape, dtype=xl.dtype)\n",
    "        x[mask] = xl.squeeze(1)\n",
    "        return x\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim=16, M=10000):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.M = M\n",
    "\n",
    "    def forward(self, x):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(self.M) / half_dim\n",
    "        emb = torch.exp(torch.arange(half_dim) * (-emb) ).type_as(x[..., None])\n",
    "        emb = x[..., None] * emb[None, ...]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "class Extractor(nn.Module):\n",
    "    def __init__(self, dim_base=128, dim=384):\n",
    "        super().__init__()\n",
    "        self.emb = SinusoidalPosEmb(dim=dim_base)\n",
    "        self.combined_dom_type_emb = nn.Embedding(5, dim_base // 2)\n",
    "        self.emb2 = SinusoidalPosEmb(dim=dim_base // 2)\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(6 * dim_base, 6 * dim_base),\n",
    "            nn.LayerNorm(6 * dim_base),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(6 * dim_base, dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, Lmax=None):\n",
    "        pos = x[\"pos\"] if Lmax is None else x[\"pos\"][:, :Lmax]\n",
    "        charge = x[\"charge\"] if Lmax is None else x[\"charge\"][:, :Lmax]\n",
    "        time = x[\"dom_time\"] if Lmax is None else x[\"dom_time\"][:, :Lmax]\n",
    "\n",
    "        combined_dom_type = x[\"combined_dom_type\"] if Lmax is None else x[\"combined_dom_type\"][:, :Lmax]\n",
    "        combined_dom_type.to(dtype=pos.dtype)\n",
    "        length = torch.log10(x[\"L0\"].to(dtype=pos.dtype))\n",
    "\n",
    "        x = torch.cat(\n",
    "            [\n",
    "                self.emb(4096 * pos).flatten(-2),\n",
    "                self.emb(1024 * charge),\n",
    "                self.emb(4096 * time),\n",
    "                self.combined_dom_type_emb(combined_dom_type),\n",
    "                self.emb2(length).unsqueeze(1).expand(-1, pos.shape[1], -1),\n",
    "            ],\n",
    "            -1,\n",
    "        )\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "class Rel_ds(nn.Module):\n",
    "    def __init__(self, dim=32):\n",
    "        super().__init__()\n",
    "        self.emb = SinusoidalPosEmb(dim=dim)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x, Lmax=None):\n",
    "        pos = x[\"pos\"] if Lmax is None else x[\"pos\"][:, :Lmax]\n",
    "        time = x[\"dom_time\"] if Lmax is None else x[\"dom_time\"][:, :Lmax]\n",
    "        ds2 = (pos[:, :, None] - pos[:, None, :]).pow(2).sum(-1) - (\n",
    "            (time[:, :, None] - time[:, None, :]) * (3e4 / 500 * 3e-1)\n",
    "        ).pow(2)\n",
    "        d = torch.sign(ds2) * torch.sqrt(torch.abs(ds2))\n",
    "        emb = self.emb(1024 * d.clip(-4, 4))\n",
    "        rel_attn = self.proj(emb)\n",
    "        return rel_attn, emb\n",
    "\n",
    "class DeepIceModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # dim=384,\n",
    "        dim_base=128,\n",
    "        depth=12,\n",
    "        head_size=32,\n",
    "        n_heads_rel=12,\n",
    "        depth_rel=4,\n",
    "        n_rel=1,\n",
    "        dim_out=1,\n",
    "        out_act = nn.Softplus(),\n",
    "        use_checkpoint=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        dim = head_size * n_heads_rel\n",
    "\n",
    "        self.extractor = Extractor(dim_base, dim)\n",
    "        self.rel_pos = Rel_ds(head_size)\n",
    "        self.sandwich = nn.ModuleList(\n",
    "            [Block_rel(dim=dim, num_heads = n_heads_rel) for i in range(depth_rel)]\n",
    "        )\n",
    "        self.cls_token = nn.Linear(dim, 1, bias=False)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                Block(\n",
    "                    dim=dim,\n",
    "                    num_heads=dim // head_size,\n",
    "                    mlp_ratio=4,\n",
    "                    drop_path=0.0 * (i / (depth - 1)),\n",
    "                    init_values=1,\n",
    "                )\n",
    "                for i in range(depth)\n",
    "            ]\n",
    "        )\n",
    "        self.proj_out = nn.Linear(dim, dim_out)\n",
    "        self.out_act = out_act\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        self.apply(self._init_weights)\n",
    "        trunc_normal_(self.cls_token.weight, std=0.02)\n",
    "        self.n_rel = n_rel\n",
    "\n",
    "    def fix_init_weight(self):\n",
    "        def rescale(param, layer_id):\n",
    "            param.div_(math.sqrt(2.0 * layer_id))\n",
    "\n",
    "        for layer_id, layer in enumerate(self.blocks):\n",
    "            rescale(layer.attn.proj.weight.data, layer_id + 1)\n",
    "            rescale(layer.mlp.fc2.weight.data, layer_id + 1)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=0.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def init_weights(self, pretrained=None):\n",
    "        def _init_weights(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                trunc_normal_(m.weight, std=0.02)\n",
    "                if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.LayerNorm):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "        self.apply(_init_weights)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {\"cls_token\"}\n",
    "\n",
    "    def forward(self, x0):\n",
    "        mask = x0[\"mask\"]\n",
    "        Lmax = mask.sum(-1).max()\n",
    "        x = self.extractor(x0, Lmax)\n",
    "        rel_pos_bias, rel_enc = self.rel_pos(x0, Lmax)\n",
    "\n",
    "        mask = mask[:, :Lmax]\n",
    "        B, _ = mask.shape\n",
    "\n",
    "        attn_mask = torch.zeros(mask.shape).type_as(rel_pos_bias)\n",
    "        attn_mask[~mask] = -torch.inf\n",
    "\n",
    "        for i, blk in enumerate(self.sandwich):\n",
    "            x, _ = blk(x, attn_mask, rel_pos_bias)\n",
    "            if i + 1 == self.n_rel:\n",
    "                rel_pos_bias = None\n",
    "\n",
    "        mask = torch.cat(\n",
    "            [\n",
    "                torch.ones(\n",
    "                    B,\n",
    "                    1,\n",
    "                ).type_as(mask),\n",
    "                mask,\n",
    "            ],\n",
    "            1,\n",
    "        )\n",
    "\n",
    "        cls_token = self.cls_token.weight.unsqueeze(0).expand(B, -1, -1)\n",
    "\n",
    "        attn_mask = torch.zeros(mask.shape, dtype=mask.dtype).type_as(cls_token)\n",
    "        attn_mask[~mask] = -torch.inf\n",
    "\n",
    "        x = torch.cat([cls_token, x], 1)\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x, _ = checkpoint.checkpoint(blk, x, None, attn_mask)\n",
    "            else:\n",
    "                x, _ = blk(x, None, attn_mask)\n",
    "\n",
    "        x = self.proj_out(x[:, 0])  # cls token\n",
    "        x = self.out_act(x)\n",
    "        return x.squeeze(1)\n",
    "\n",
    "    def get_attn_weights(self, x0):\n",
    "        mask = x0[\"mask\"]\n",
    "        Lmax = mask.sum(-1).max()\n",
    "        x = self.extractor(x0, Lmax)\n",
    "        rel_pos_bias, rel_enc = self.rel_pos(x0, Lmax)\n",
    "\n",
    "        mask = mask[:, :Lmax]\n",
    "        B, _ = mask.shape\n",
    "\n",
    "        attn_mask = torch.zeros(mask.shape).type_as(rel_pos_bias)\n",
    "        attn_mask[~mask] = -torch.inf\n",
    "\n",
    "        attn_weight_rel_list = []\n",
    "        for i, blk in enumerate(self.sandwich):\n",
    "            x, attn_weight_rel = blk(x, attn_mask, rel_pos_bias)\n",
    "            attn_weight_rel_list.append(attn_weight_rel)\n",
    "            if i + 1 == self.n_rel:\n",
    "                rel_pos_bias = None\n",
    "\n",
    "        attn_weight_rel_tensor = torch.stack(attn_weight_rel_list, dim=1)\n",
    "\n",
    "        mask = torch.cat(\n",
    "            [\n",
    "                torch.ones(\n",
    "                    B,\n",
    "                    1,\n",
    "                ).type_as(mask),\n",
    "                mask,\n",
    "            ],\n",
    "            1,\n",
    "        )\n",
    "\n",
    "        cls_token = self.cls_token.weight.unsqueeze(0).expand(B, -1, -1)\n",
    "\n",
    "        attn_mask = torch.zeros(mask.shape, dtype=mask.dtype).type_as(cls_token)\n",
    "        attn_mask[~mask] = -torch.inf\n",
    "\n",
    "        x = torch.cat([cls_token, x], 1)\n",
    "\n",
    "        attn_weight_list = []\n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x, attn_weight = checkpoint.checkpoint(blk, x, None, attn_mask)\n",
    "                attn_weight_list.append(attn_weight)\n",
    "            else:\n",
    "                x, attn_weight = blk(x, None, attn_mask)\n",
    "                attn_weight_list.append(attn_weight)\n",
    "\n",
    "        attn_weight_tensor = torch.stack(attn_weight_list, dim=1)\n",
    "\n",
    "        x = self.proj_out(x[:, 0])  # cls token\n",
    "        x = self.out_act(x)\n",
    "        return {\n",
    "            \"mask\": attn_mask,\n",
    "            \"attn_weights\": attn_weight_tensor,\n",
    "            \"rel_attn_weights\": attn_weight_rel_tensor,\n",
    "        }\n",
    "\n",
    "    # def forward(self, x0, return_attention_weights=False):\n",
    "    #     mask = x0[\"mask\"]\n",
    "    #     Lmax = mask.sum(-1).max()\n",
    "    #     x = self.extractor(x0, Lmax)\n",
    "    #     rel_pos_bias, rel_enc = self.rel_pos(x0, Lmax)\n",
    "\n",
    "    #     mask = mask[:, :Lmax]\n",
    "    #     B, _ = mask.shape\n",
    "        \n",
    "    #     attn_mask = torch.zeros(mask.shape).type_as(rel_pos_bias)\n",
    "    #     attn_mask[~mask] = -torch.inf\n",
    "\n",
    "    #     if return_attention_weights:\n",
    "    #         attn_weight_rel_list = []\n",
    "    #         for i, blk in enumerate(self.sandwich):\n",
    "    #             x, attn_weight_rel = blk(x, attn_mask, rel_pos_bias)\n",
    "    #             attn_weight_rel_list.append(attn_weight_rel)\n",
    "    #             if i + 1 == self.n_rel:\n",
    "    #                 rel_pos_bias = None\n",
    "    #         attn_weight_rel_tensor = torch.stack(attn_weight_rel_list, dim=1)\n",
    "    #     else:\n",
    "    #         for i, blk in enumerate(self.sandwich):\n",
    "    #             x, _ = blk(x, attn_mask, rel_pos_bias)\n",
    "    #             if i + 1 == self.n_rel:\n",
    "    #                 rel_pos_bias = None\n",
    "\n",
    "        \n",
    "\n",
    "    #     mask = torch.cat(\n",
    "    #         [torch.ones(B, 1,).type_as(mask), mask], 1\n",
    "    #     )\n",
    "\n",
    "    #     cls_token = self.cls_token.weight.unsqueeze(0).expand(B, -1, -1)\n",
    "\n",
    "    #     attn_mask = torch.zeros(mask.shape, dtype=mask.dtype).type_as(cls_token)\n",
    "    #     attn_mask[~mask] = -torch.inf\n",
    "        \n",
    "    #     x = torch.cat([cls_token, x], 1)\n",
    "        \n",
    "    #     if return_attention_weights:\n",
    "    #         attn_weight_list = []\n",
    "    #         for blk in self.blocks:\n",
    "    #             if self.use_checkpoint:\n",
    "    #                 x,attn_weight = checkpoint.checkpoint(blk, x, None, attn_mask)\n",
    "    #                 attn_weight_list.append(attn_weight)\n",
    "    #             else:\n",
    "    #                 x,attn_weight = blk(x, None, attn_mask)\n",
    "    #                 attn_weight_list.append(attn_weight)\n",
    "    #         attn_weight_tensor = torch.stack(attn_weight_list, dim=1)\n",
    "    #     else:\n",
    "    #         for blk in self.blocks:\n",
    "    #             if self.use_checkpoint:\n",
    "    #                 x,_ = checkpoint.checkpoint(blk, x, None, attn_mask)\n",
    "    #             else:\n",
    "    #                 x,_ = blk(x, None, attn_mask)\n",
    "            \n",
    "\n",
    "    #     x = self.proj_out(x[:, 0])  # cls token\n",
    "    #     x = self.out_act(x)\n",
    "\n",
    "    #     if return_attention_weights:\n",
    "    #         return {\n",
    "    #             \"pred\":x.squeeze(1), \n",
    "    #             \"mask\":attn_mask,\n",
    "    #             \"attn_weights\": attn_weight_tensor, \n",
    "    #             \"rel_attn_weights\": attn_weight_rel_tensor\n",
    "    #             }\n",
    "    #     else: \n",
    "    #         return {\n",
    "    #             \"pred\":x.squeeze(1),\n",
    "    #             }\n",
    "\n",
    "    # def forward(self, x0):\n",
    "    #     mask = x0[\"mask\"]\n",
    "    #     Lmax = mask.sum(-1).max()\n",
    "    #     x = self.extractor(x0, Lmax)\n",
    "    #     rel_pos_bias, rel_enc = self.rel_pos(x0, Lmax)\n",
    "\n",
    "    #     mask = mask[:, :Lmax]\n",
    "    #     B, _ = mask.shape\n",
    "        \n",
    "    #     attn_mask = torch.zeros(mask.shape).type_as(rel_pos_bias)\n",
    "    #     attn_mask[~mask] = -torch.inf\n",
    "\n",
    "    #     attn_weight_rel_list = []\n",
    "    #     for i, blk in enumerate(self.sandwich):\n",
    "\n",
    "    #         x, attn_weight_rel = blk(x, attn_mask, rel_pos_bias)\n",
    "    #         attn_weight_rel_list.append(attn_weight_rel)\n",
    "    #         if i + 1 == self.n_rel:\n",
    "    #             rel_pos_bias = None\n",
    "\n",
    "    #     attn_weight_rel_tensor = torch.stack(attn_weight_rel_list, dim=1)\n",
    "\n",
    "    #     mask = torch.cat(\n",
    "    #         [torch.ones(B, 1,).type_as(mask), mask], 1\n",
    "    #     )\n",
    "\n",
    "    #     cls_token = self.cls_token.weight.unsqueeze(0).expand(B, -1, -1)\n",
    "\n",
    "    #     attn_mask = torch.zeros(mask.shape, dtype=mask.dtype).type_as(cls_token)\n",
    "    #     attn_mask[~mask] = -torch.inf\n",
    "        \n",
    "    #     x = torch.cat([cls_token, x], 1)\n",
    "\n",
    "    #     attn_weight_list = []\n",
    "    #     for blk in self.blocks:\n",
    "    #         if self.use_checkpoint:\n",
    "    #             x,attn_weight = checkpoint.checkpoint(blk, x, None, attn_mask)\n",
    "    #             attn_weight_list.append(attn_weight)\n",
    "    #         else:\n",
    "    #             x,attn_weight = blk(x, None, attn_mask)\n",
    "    #             attn_weight_list.append(attn_weight)\n",
    "\n",
    "    #     attn_weight_tensor = torch.stack(attn_weight_list, dim=1)\n",
    "\n",
    "    #     x = self.proj_out(x[:, 0])  # cls token\n",
    "    #     x = self.out_act(x)\n",
    "    #     return {\n",
    "    #         \"pred\":x.squeeze(1), \n",
    "    #         \"mask\":attn_mask,\n",
    "    #         \"attn_weights\": attn_weight_tensor, \n",
    "    #         \"rel_attn_weights\": attn_weight_rel_tensor\n",
    "    #         }\n",
    "    \n",
    "    # def forward(self, x0):\n",
    "    #     mask = x0[\"mask\"]\n",
    "    #     Lmax = mask.sum(-1).max()\n",
    "    #     x = self.extractor(x0, Lmax)\n",
    "    #     rel_pos_bias, rel_enc = self.rel_pos(x0, Lmax)\n",
    "    #     # nbs = get_nbs(x0, Lmax)\n",
    "    #     mask = mask[:, :Lmax]\n",
    "    #     B, _ = mask.shape\n",
    "\n",
    "    #     attn_mask = torch.zeros(mask.shape).type_as(\n",
    "    #         rel_pos_bias\n",
    "    #     )\n",
    "    #     attn_mask[~mask] = -torch.inf\n",
    "\n",
    "    #     for i, blk in enumerate(self.sandwich):\n",
    "    #         # if isinstance(blk, LocalBlock):\n",
    "    #         #     x = blk(x, nbs, mask, rel_enc)\n",
    "    #         # else:\n",
    "    #         x = blk(x, attn_mask, rel_pos_bias)\n",
    "    #         if i + 1 == self.n_rel:\n",
    "    #             rel_pos_bias = None\n",
    "\n",
    "    #     mask = torch.cat(\n",
    "    #         [\n",
    "    #             torch.ones(\n",
    "    #                 B,\n",
    "    #                 1,\n",
    "    #             ).type_as(mask),\n",
    "    #             mask,\n",
    "    #         ],\n",
    "    #         1,\n",
    "    #     )\n",
    "    #     cls_token = self.cls_token.weight.unsqueeze(0).expand(B, -1, -1)\n",
    "\n",
    "    #     attn_mask = torch.zeros(mask.shape, dtype=mask.dtype).type_as(cls_token)\n",
    "    #     attn_mask[~mask] = -torch.inf\n",
    "\n",
    "    #     x = torch.cat([cls_token, x], 1)\n",
    "\n",
    "    #     for blk in self.blocks:\n",
    "    #         if self.use_checkpoint:\n",
    "    #             x = checkpoint.checkpoint(blk, x, None, attn_mask)\n",
    "    #         else:\n",
    "    #             x = blk(x, None, attn_mask)\n",
    "\n",
    "    #     x = self.proj_out(x[:, 0])  # cls token\n",
    "    #     x = self.out_act(x)\n",
    "    #     return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepIceModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # dim=384,\n",
    "        dim_base=128,\n",
    "        depth=12,\n",
    "        head_size=32,\n",
    "        n_heads_rel=12,\n",
    "        depth_rel=4,\n",
    "        n_rel=1,\n",
    "        dim_out=1,\n",
    "        out_act = nn.Softplus(),\n",
    "        use_checkpoint=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        dim = head_size * n_heads_rel\n",
    "\n",
    "        self.extractor = Extractor(dim_base, dim)\n",
    "        self.rel_pos = Rel_ds(head_size)\n",
    "        self.sandwich = nn.ModuleList(\n",
    "            [Block_rel(dim=dim, num_heads = n_heads_rel) for i in range(depth_rel)]\n",
    "        )\n",
    "        self.cls_token = nn.Linear(dim, 1, bias=False)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                Block(\n",
    "                    dim=dim,\n",
    "                    num_heads=dim // head_size,\n",
    "                    mlp_ratio=4,\n",
    "                    drop_path=0.0 * (i / (depth - 1)),\n",
    "                    init_values=1,\n",
    "                )\n",
    "                for i in range(depth)\n",
    "            ]\n",
    "        )\n",
    "        self.proj_out = nn.Linear(dim, dim_out)\n",
    "        self.out_act = out_act\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        self.apply(self._init_weights)\n",
    "        trunc_normal_(self.cls_token.weight, std=0.02)\n",
    "        self.n_rel = n_rel\n",
    "\n",
    "    def fix_init_weight(self):\n",
    "        def rescale(param, layer_id):\n",
    "            param.div_(math.sqrt(2.0 * layer_id))\n",
    "\n",
    "        for layer_id, layer in enumerate(self.blocks):\n",
    "            rescale(layer.attn.proj.weight.data, layer_id + 1)\n",
    "            rescale(layer.mlp.fc2.weight.data, layer_id + 1)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=0.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def init_weights(self, pretrained=None):\n",
    "        def _init_weights(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                trunc_normal_(m.weight, std=0.02)\n",
    "                if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.LayerNorm):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "        self.apply(_init_weights)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {\"cls_token\"}\n",
    "\n",
    "    def forward(self, x0):\n",
    "        mask = x0[\"mask\"]\n",
    "        Lmax = mask.sum(-1).max()\n",
    "        x = self.extractor(x0, Lmax)\n",
    "        rel_pos_bias, rel_enc = self.rel_pos(x0, Lmax)\n",
    "\n",
    "        mask = mask[:, :Lmax]\n",
    "        B, _ = mask.shape\n",
    "\n",
    "        attn_mask = torch.zeros(mask.shape).type_as(rel_pos_bias)\n",
    "        attn_mask[~mask] = -torch.inf\n",
    "\n",
    "        for i, blk in enumerate(self.sandwich):\n",
    "            x, _ = blk(x, attn_mask, rel_pos_bias)\n",
    "            if i + 1 == self.n_rel:\n",
    "                rel_pos_bias = None\n",
    "\n",
    "        mask = torch.cat(\n",
    "            [\n",
    "                torch.ones(\n",
    "                    B,\n",
    "                    1,\n",
    "                ).type_as(mask),\n",
    "                mask,\n",
    "            ],\n",
    "            1,\n",
    "        )\n",
    "\n",
    "        cls_token = self.cls_token.weight.unsqueeze(0).expand(B, -1, -1)\n",
    "\n",
    "        attn_mask = torch.zeros(mask.shape, dtype=mask.dtype).type_as(cls_token)\n",
    "        attn_mask[~mask] = -torch.inf\n",
    "\n",
    "        x = torch.cat([cls_token, x], 1)\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x, _ = checkpoint.checkpoint(blk, x, None, attn_mask)\n",
    "            else:\n",
    "                x, _ = blk(x, None, attn_mask)\n",
    "\n",
    "        x = self.proj_out(x[:, 0])  # cls token\n",
    "        x = self.out_act(x)\n",
    "        return x.squeeze(1)\n",
    "\n",
    "    def get_attn_weights(self, x0):\n",
    "        mask = x0[\"mask\"]\n",
    "        Lmax = mask.sum(-1).max()\n",
    "        x = self.extractor(x0, Lmax)\n",
    "        rel_pos_bias, rel_enc = self.rel_pos(x0, Lmax)\n",
    "\n",
    "        mask = mask[:, :Lmax]\n",
    "        B, _ = mask.shape\n",
    "\n",
    "        attn_mask = torch.zeros(mask.shape).type_as(rel_pos_bias)\n",
    "        attn_mask[~mask] = -torch.inf\n",
    "\n",
    "        attn_weight_rel_list = []\n",
    "        for i, blk in enumerate(self.sandwich):\n",
    "            x, attn_weight_rel = blk(x, attn_mask, rel_pos_bias)\n",
    "            attn_weight_rel_list.append(attn_weight_rel)\n",
    "            if i + 1 == self.n_rel:\n",
    "                rel_pos_bias = None\n",
    "\n",
    "        attn_weight_rel_tensor = torch.stack(attn_weight_rel_list, dim=1)\n",
    "\n",
    "        mask = torch.cat(\n",
    "            [\n",
    "                torch.ones(\n",
    "                    B,\n",
    "                    1,\n",
    "                ).type_as(mask),\n",
    "                mask,\n",
    "            ],\n",
    "            1,\n",
    "        )\n",
    "\n",
    "        cls_token = self.cls_token.weight.unsqueeze(0).expand(B, -1, -1)\n",
    "\n",
    "        attn_mask = torch.zeros(mask.shape, dtype=mask.dtype).type_as(cls_token)\n",
    "        attn_mask[~mask] = -torch.inf\n",
    "\n",
    "        x = torch.cat([cls_token, x], 1)\n",
    "\n",
    "        attn_weight_list = []\n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x, attn_weight = checkpoint.checkpoint(blk, x, None, attn_mask)\n",
    "                attn_weight_list.append(attn_weight)\n",
    "            else:\n",
    "                x, attn_weight = blk(x, None, attn_mask)\n",
    "                attn_weight_list.append(attn_weight)\n",
    "\n",
    "        attn_weight_tensor = torch.stack(attn_weight_list, dim=1)\n",
    "\n",
    "        x = self.proj_out(x[:, 0])  # cls token\n",
    "        x = self.out_act(x)\n",
    "        return {\n",
    "            \"mask\": attn_mask,\n",
    "            \"attn_weights\": attn_weight_tensor,\n",
    "            \"rel_attn_weights\": attn_weight_rel_tensor,\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Features: torch.Size([256, 9])\n",
      "Predicted: torch.Size([256])\n",
      "Mask: torch.Size([256, 10])\n",
      "Rel Attention: torch.Size([256, 4, 12, 9, 9])\n",
      "Attention: torch.Size([256, 6, 12, 10, 10])\n",
      "\n",
      "Batch 2\n",
      "Features: torch.Size([256, 9])\n",
      "Predicted: torch.Size([256])\n",
      "Mask: torch.Size([256, 10])\n",
      "Rel Attention: torch.Size([256, 4, 12, 9, 9])\n",
      "Attention: torch.Size([256, 6, 12, 10, 10])\n",
      "\n",
      "Batch 3\n",
      "Features: torch.Size([256, 9])\n",
      "Predicted: torch.Size([256])\n",
      "Mask: torch.Size([256, 10])\n",
      "Rel Attention: torch.Size([256, 4, 12, 9, 9])\n",
      "Attention: torch.Size([256, 6, 12, 10, 10])\n",
      "\n",
      "Batch 4\n",
      "Features: torch.Size([256, 9])\n",
      "Predicted: torch.Size([256])\n",
      "Mask: torch.Size([256, 10])\n",
      "Rel Attention: torch.Size([256, 4, 12, 9, 9])\n",
      "Attention: torch.Size([256, 6, 12, 10, 10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chunk_csv_train = [\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_1.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_2.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_3.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_4.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_5.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_6.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_7.csv\",\n",
    "]\n",
    "chunk_csv_test = [\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_1.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_2.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_3.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_4.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_5.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_6.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_7.csv\",\n",
    "]\n",
    "chunk_csv_val = [\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_1.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_2.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_3.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_4.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_5.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_6.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_7.csv\",\n",
    "]\n",
    "batch_sizes = [512, 256, 128, 64, 32, 16, 8]\n",
    "truth_table = \"truth\"\n",
    "db_path = \"/groups/icecube/petersen/GraphNetDatabaseRepository/Upgrade_Data/sqlite3/dev_step4_upgrade_028_with_noise_dynedge_pulsemap_v3_merger_aftercrash.db\"\n",
    "pulsemap = \"SplitInIcePulses_dynedge_v2_Pulses\"\n",
    "input_cols =  [\"dom_x\", \"dom_y\", \"dom_z\", \"dom_time\", \"charge\", \"rde\", \"dom_type\"]\n",
    "target_cols = \"inelasticity\"\n",
    "\n",
    "dataset = ChunkDataset(\n",
    "    db_path=db_path, \n",
    "    chunk_csvs=chunk_csv_train, \n",
    "    pulsemap=pulsemap, \n",
    "    truth_table=truth_table, \n",
    "    target_cols=target_cols, \n",
    "    input_cols=input_cols\n",
    "    )\n",
    "\n",
    "dl = DataLoader(\n",
    "    dataset=dataset,\n",
    "    collate_fn=collate_fn,\n",
    "    batch_sampler=ChunkSampler(chunk_csv_train, batch_sizes),\n",
    "    num_workers=0,\n",
    "    )\n",
    "\n",
    "model = DeepIceModel(\n",
    "        dim=384,\n",
    "        dim_base=128, #128\n",
    "        depth=6,\n",
    "        use_checkpoint=False,\n",
    "        head_size=32,\n",
    "        depth_rel=4,\n",
    "        n_rel=1,\n",
    "        )\n",
    "\n",
    "return_attention_weights = True\n",
    "for i, (features, truth) in enumerate(dl):\n",
    "    \n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    pred = model(features,)\n",
    "\n",
    "    print(f\"Batch {i + 1}\")\n",
    "    print(\"Features:\", features['charge'].shape)\n",
    "    # print(\"Truth:\", truth.shape)\n",
    "    print(\"Predicted:\", pred.shape)\n",
    "    if return_attention_weights:\n",
    "      output= model.get_attn_weights(features)\n",
    "      print(\"Mask:\", output[\"mask\"].shape)\n",
    "      print(\"Rel Attention:\", output[\"rel_attn_weights\"].shape)\n",
    "      print(\"Attention:\", output[\"attn_weights\"].shape)\n",
    "    print()\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class Extractor(nn.Module):\n",
    "#     def __init__(self, dim_base=128, dim=384):\n",
    "#         super().__init__()\n",
    "#         self.emb = SinusoidalPosEmb(dim=dim_base)\n",
    "#         self.dom_type_rde_emb = nn.Embedding(5, dim_base // 2)\n",
    "#         self.emb2 = SinusoidalPosEmb(dim=dim_base // 2)\n",
    "#         self.proj = nn.Sequential(\n",
    "#             nn.Linear(6 * dim_base, 6 * dim_base),\n",
    "#             nn.LayerNorm(6 * dim_base),\n",
    "#             nn.GELU(),\n",
    "#             nn.Linear(6 * dim_base, dim),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x, L0=None):\n",
    "#         Lmax = L0.max() if L0 is not None else max(len(item) for item in x['pos'])\n",
    "#         pos = x[\"pos\"][:, :Lmax]\n",
    "#         charge = x[\"charge\"][:, :Lmax]\n",
    "#         time = x[\"time\"][:, :Lmax]\n",
    "#         dom_type_rde = x[\"dom_type_rde\"][:, :Lmax]\n",
    "#         length = torch.log10(L0.to(dtype=pos.dtype))\n",
    "\n",
    "#         x = torch.cat(\n",
    "#             [\n",
    "#                 self.emb(4096 * pos).flatten(-2),\n",
    "#                 self.emb(1024 * charge),\n",
    "#                 self.emb(4096 * time),\n",
    "#                 self.dom_type_rde_emb(dom_type_rde),\n",
    "#                 self.emb2(length).unsqueeze(1).expand(-1, pos.shape[1], -1),\n",
    "#             ],\n",
    "#             -1,\n",
    "#         )\n",
    "#         x = self.proj(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "\n",
    "# class Extractor(nn.Module):\n",
    "#     def __init__(self, dim_base=128, dim=384):\n",
    "#         super().__init__()\n",
    "#         self.emb = SinusoidalPosEmb(dim=dim_base)\n",
    "#         self.aux_emb = nn.Embedding(2, dim_base // 2)\n",
    "#         self.emb2 = SinusoidalPosEmb(dim=dim_base // 2)\n",
    "#         self.proj = nn.Sequential(\n",
    "#             nn.Linear(6 * dim_base, 6 * dim_base),\n",
    "#             nn.LayerNorm(6 * dim_base),\n",
    "#             nn.GELU(),\n",
    "#             nn.Linear(6 * dim_base, dim),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x, Lmax=None):\n",
    "#         pos = x[\"pos\"] if Lmax is None else x[\"pos\"][:, :Lmax]\n",
    "#         charge = x[\"charge\"] if Lmax is None else x[\"charge\"][:, :Lmax]\n",
    "#         time = x[\"time\"] if Lmax is None else x[\"time\"][:, :Lmax]\n",
    "#         auxiliary = x[\"auxiliary\"] if Lmax is None else x[\"auxiliary\"][:, :Lmax]\n",
    "#         qe = x[\"qe\"] if Lmax is None else x[\"qe\"][:, :Lmax]\n",
    "#         ice_properties = (\n",
    "#             x[\"ice_properties\"] if Lmax is None else x[\"ice_properties\"][:, :Lmax]\n",
    "#         )\n",
    "#         length = torch.log10(x[\"L0\"].to(dtype=pos.dtype))\n",
    "\n",
    "#         x = torch.cat(\n",
    "#             [\n",
    "#                 self.emb(4096 * pos).flatten(-2),\n",
    "#                 self.emb(1024 * charge),\n",
    "#                 self.emb(4096 * time),\n",
    "#                 self.aux_emb(auxiliary),\n",
    "#                 self.emb2(length).unsqueeze(1).expand(-1, pos.shape[1], -1),\n",
    "#             ],\n",
    "#             -1,\n",
    "#         )\n",
    "#         x = self.proj(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "\n",
    "# class LocalBlock(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         dim=192,\n",
    "#         num_heads=192 // 64,\n",
    "#         mlp_ratio=4,\n",
    "#         drop_path=0,\n",
    "#         init_values=1,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         self.proj_rel_bias = nn.Linear(dim // num_heads, dim // num_heads)\n",
    "#         self.block = Block_rel(\n",
    "#             dim=dim,\n",
    "#             num_heads=num_heads,\n",
    "#             mlp_ratio=mlp_ratio,\n",
    "#             drop_path=drop_path,\n",
    "#             init_values=init_values,\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x, nbs, key_padding_mask=None, rel_pos_bias=None):\n",
    "#         B, Lmax, C = x.shape\n",
    "#         mask = (\n",
    "#             key_padding_mask\n",
    "#             if not (key_padding_mask is None)\n",
    "#             else torch.ones(B, Lmax, dtype=torch.bool, device=x.deice)\n",
    "#         )\n",
    "\n",
    "#         m = torch.gather(mask.unsqueeze(1).expand(-1, Lmax, -1), 2, nbs)\n",
    "#         attn_mask = torch.zeros(m.shape, device=m.device)\n",
    "#         attn_mask[~mask] = -torch.inf\n",
    "#         attn_mask = attn_mask[mask]\n",
    "\n",
    "#         if rel_pos_bias is not None:\n",
    "#             rel_pos_bias = torch.gather(\n",
    "#                 rel_pos_bias,\n",
    "#                 2,\n",
    "#                 nbs.unsqueeze(-1).expand(-1, -1, -1, rel_pos_bias.shape[-1]),\n",
    "#             )\n",
    "#             rel_pos_bias = rel_pos_bias[mask]\n",
    "#             rel_pos_bias = self.proj_rel_bias(rel_pos_bias).unsqueeze(1)\n",
    "\n",
    "#         xl = torch.gather(\n",
    "#             x.unsqueeze(1).expand(-1, Lmax, -1, -1),\n",
    "#             2,\n",
    "#             nbs.unsqueeze(-1).expand(-1, -1, -1, C),\n",
    "#         )\n",
    "#         xl = xl[mask]\n",
    "#         # modify only the node (0th element)\n",
    "#         # print(xl[:,:1].shape,rel_pos_bias.shape,attn_mask[:,:1].shape,xl.shape)\n",
    "#         xl = self.block(\n",
    "#             xl[:, :1],\n",
    "#             rel_pos_bias=rel_pos_bias,\n",
    "#             key_padding_mask=attn_mask[:, :1],\n",
    "#             kv=xl,\n",
    "#         )\n",
    "#         x = torch.zeros(x.shape, device=x.device, dtype=xl.dtype)\n",
    "#         x[mask] = xl.squeeze(1)\n",
    "#         return x\n",
    "class DropPath(nn.Module):\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return \"p={}\".format(self.drop_prob)\n",
    "\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        hidden_features=None,\n",
    "        out_features=None,\n",
    "        act_layer=nn.GELU,\n",
    "        drop=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        # x = self.drop(x)\n",
    "        # commit this for the orignal BERT implement\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# BEiTv2 block\n",
    "class Block(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads,\n",
    "        mlp_ratio=4.0,\n",
    "        qkv_bias=False,\n",
    "        qk_scale=None,\n",
    "        drop=0.0,\n",
    "        attn_drop=0.0,\n",
    "        drop_path=0.0,\n",
    "        init_values=None,\n",
    "        act_layer=nn.GELU,\n",
    "        norm_layer=nn.LayerNorm,\n",
    "        window_size=None,\n",
    "        attn_head_dim=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            dim, num_heads, dropout=drop, batch_first=True\n",
    "        )\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(\n",
    "            in_features=dim,\n",
    "            hidden_features=mlp_hidden_dim,\n",
    "            act_layer=act_layer,\n",
    "            drop=drop,\n",
    "        )\n",
    "\n",
    "        if init_values is not None:\n",
    "            self.gamma_1 = nn.Parameter(\n",
    "                init_values * torch.ones((dim)), requires_grad=True\n",
    "            )\n",
    "            self.gamma_2 = nn.Parameter(\n",
    "                init_values * torch.ones((dim)), requires_grad=True\n",
    "            )\n",
    "        else:\n",
    "            self.gamma_1, self.gamma_2 = None, None\n",
    "\n",
    "    def forward(self, x, attn_mask=None, key_padding_mask=None):\n",
    "        if self.gamma_1 is None:\n",
    "            xn = self.norm1(x)\n",
    "            x_attn, attn_weights = self.attn(\n",
    "                    xn,\n",
    "                    xn,\n",
    "                    xn,\n",
    "                    attn_mask=attn_mask,\n",
    "                    key_padding_mask=key_padding_mask,\n",
    "                    need_weights=True,\n",
    "                )\n",
    "            x = x + self.drop_path(x_attn)\n",
    "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        else:\n",
    "            xn = self.norm1(x)\n",
    "            x_attn, attn_weights = self.attn(\n",
    "                    xn,\n",
    "                    xn,\n",
    "                    xn,\n",
    "                    attn_mask=attn_mask,\n",
    "                    key_padding_mask=key_padding_mask,\n",
    "                    need_weights=True,\n",
    "                )\n",
    "            x = x + self.drop_path(x_attn)\n",
    "            x = x + self.drop_path(self.gamma_2 * self.mlp(self.norm2(x)))\n",
    "            print(attn_weights)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Attention_rel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads=8,\n",
    "        qkv_bias=False,\n",
    "        qk_scale=None,\n",
    "        attn_drop=0.0,\n",
    "        proj_drop=0.0,\n",
    "        attn_head_dim=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        if attn_head_dim is not None:\n",
    "            head_dim = attn_head_dim\n",
    "        all_head_dim = head_dim * self.num_heads\n",
    "        self.scale = qk_scale or head_dim**-0.5\n",
    "\n",
    "        self.proj_q = nn.Linear(dim, all_head_dim, bias=False)\n",
    "        self.proj_k = nn.Linear(dim, all_head_dim, bias=False)\n",
    "        self.proj_v = nn.Linear(dim, all_head_dim, bias=False)\n",
    "        if qkv_bias:\n",
    "            self.q_bias = nn.Parameter(torch.zeros(all_head_dim))\n",
    "            self.v_bias = nn.Parameter(torch.zeros(all_head_dim))\n",
    "        else:\n",
    "            self.q_bias = None\n",
    "            self.v_bias = None\n",
    "\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(all_head_dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, q, k, v, rel_pos_bias=None, key_padding_mask=None):\n",
    "        # rel_pos_bias: B L L C/h\n",
    "        # key_padding_mask - float with -inf\n",
    "        B, N, C = q.shape\n",
    "        # qkv_bias = None\n",
    "        # if self.q_bias is not None:\n",
    "        #    qkv_bias = torch.cat((self.q_bias, torch.zeros_like(self.v_bias, requires_grad=False), self.v_bias))\n",
    "        # qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        # qkv = F.linear(input=x, weight=self.qkv.weight, bias=qkv_bias)\n",
    "        # qkv = qkv.reshape(B, N, 3, self.num_heads, -1).permute(2, 0, 3, 1, 4)\n",
    "        # q, k, v = qkv[0], qkv[1], qkv[2]   # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        q = F.linear(input=q, weight=self.proj_q.weight, bias=self.q_bias)\n",
    "        q = q.reshape(B, N, self.num_heads, -1).permute(0, 2, 1, 3)\n",
    "        k = F.linear(input=k, weight=self.proj_k.weight, bias=None)\n",
    "        k = k.reshape(B, k.shape[1], self.num_heads, -1).permute(0, 2, 1, 3)\n",
    "        v = F.linear(input=v, weight=self.proj_v.weight, bias=self.v_bias)\n",
    "        v = v.reshape(B, v.shape[1], self.num_heads, -1).permute(0, 2, 1, 3)\n",
    "\n",
    "        q = q * self.scale\n",
    "        attn = q @ k.transpose(-2, -1)\n",
    "        if rel_pos_bias is not None:\n",
    "            bias = torch.einsum(\"bhic,bijc->bhij\", q, rel_pos_bias)\n",
    "            attn = attn + bias\n",
    "        if key_padding_mask is not None:\n",
    "            assert (\n",
    "                key_padding_mask.dtype == torch.float32\n",
    "                or key_padding_mask.dtype == torch.float16\n",
    "            ), \"incorrect mask dtype\"\n",
    "            bias = torch.min(key_padding_mask[:, None, :], key_padding_mask[:, :, None])\n",
    "            bias[\n",
    "                torch.max(key_padding_mask[:, None, :], key_padding_mask[:, :, None])\n",
    "                < 0\n",
    "            ] = 0\n",
    "            # print(bias.shape,bias.min(),bias.max())\n",
    "            attn = attn + bias.unsqueeze(1)\n",
    "\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2)\n",
    "        if rel_pos_bias is not None:\n",
    "            x = x + torch.einsum(\"bhij,bijc->bihc\", attn, rel_pos_bias)\n",
    "        x = x.reshape(B, N, -1)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# BEiTv2 block\n",
    "class Block_rel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads,\n",
    "        mlp_ratio=4.0,\n",
    "        qkv_bias=False,\n",
    "        qk_scale=None,\n",
    "        drop=0.0,\n",
    "        attn_drop=0.0,\n",
    "        drop_path=0.0,\n",
    "        init_values=None,\n",
    "        act_layer=nn.GELU,\n",
    "        norm_layer=nn.LayerNorm,\n",
    "        window_size=None,\n",
    "        attn_head_dim=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = Attention_rel(\n",
    "            dim, num_heads, attn_drop=attn_drop, qkv_bias=qkv_bias\n",
    "        )\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(\n",
    "            in_features=dim,\n",
    "            hidden_features=mlp_hidden_dim,\n",
    "            act_layer=act_layer,\n",
    "            drop=drop,\n",
    "        )\n",
    "\n",
    "        if init_values is not None:\n",
    "            self.gamma_1 = nn.Parameter(\n",
    "                init_values * torch.ones((dim)), requires_grad=True\n",
    "            )\n",
    "            self.gamma_2 = nn.Parameter(\n",
    "                init_values * torch.ones((dim)), requires_grad=True\n",
    "            )\n",
    "        else:\n",
    "            self.gamma_1, self.gamma_2 = None, None\n",
    "\n",
    "    def forward(self, x, key_padding_mask=None, rel_pos_bias=None, kv=None):\n",
    "        if self.gamma_1 is None:\n",
    "            xn = self.norm1(x)\n",
    "            kv = xn if kv is None else self.norm1(kv)\n",
    "            x = x + self.drop_path(\n",
    "                self.attn(\n",
    "                    xn,\n",
    "                    kv,\n",
    "                    kv,\n",
    "                    rel_pos_bias=rel_pos_bias,\n",
    "                    key_padding_mask=key_padding_mask,\n",
    "                )\n",
    "            )\n",
    "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        else:\n",
    "            xn = self.norm1(x)\n",
    "            kv = xn if kv is None else self.norm1(kv)\n",
    "            x = x + self.drop_path(\n",
    "                self.gamma_1\n",
    "                * self.drop_path(\n",
    "                    self.attn(\n",
    "                        xn,\n",
    "                        kv,\n",
    "                        kv,\n",
    "                        rel_pos_bias=rel_pos_bias,\n",
    "                        key_padding_mask=key_padding_mask,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            x = x + self.drop_path(self.gamma_2 * self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim=16, M=10000):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.M = M\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(self.M) / half_dim\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * (-emb))\n",
    "        emb = x[..., None] * emb[None, ...]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "class Extractor(nn.Module):\n",
    "    def __init__(self, dim_base=128, dim=384):\n",
    "        super().__init__()\n",
    "        self.emb = SinusoidalPosEmb(dim=dim_base)\n",
    "        self.combined_dom_type_linear = nn.Linear(5, dim_base // 2, bias=False)\n",
    "        self.emb2 = SinusoidalPosEmb(dim=dim_base // 2)\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(6 * dim_base, 6 * dim_base),\n",
    "            nn.LayerNorm(6 * dim_base),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(6 * dim_base, dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, L0=None):\n",
    "        Lmax = L0.max().item() if L0 is not None else max(len(item) for item in x['pos'])\n",
    "        pos = x[\"pos\"] if Lmax is None else x[\"pos\"][:, :Lmax]\n",
    "        charge = x[\"charge\"] if Lmax is None else x[\"charge\"][:, :Lmax]\n",
    "        time = x[\"time\"] if Lmax is None else x[\"time\"][:, :Lmax]\n",
    "\n",
    "        combined_dom_type = x[\"combined_dom_type\"] if Lmax is None else x[\"combined_dom_type\"][:, :Lmax]\n",
    "        length = torch.log10(x[\"L0\"].to(dtype=pos.dtype))\n",
    "\n",
    "        x = torch.cat(\n",
    "            [\n",
    "                self.emb(4096 * pos).flatten(-2),\n",
    "                self.emb(1024 * charge),\n",
    "                self.emb(4096 * time),\n",
    "                self.combined_dom_type_linear(combined_dom_type),\n",
    "                self.emb2(length).unsqueeze(1).expand(-1, pos.shape[1], -1),\n",
    "            ],\n",
    "            -1,\n",
    "        )\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "# class Extractor(nn.Module):\n",
    "#     def __init__(self, dim_base=128, dim=384):\n",
    "#         super().__init__()\n",
    "#         self.emb = SinusoidalPosEmb(dim=dim_base)\n",
    "#         self.dom_type_rde_linear = nn.Linear(5, dim_base // 2, bias=False)\n",
    "#         self.emb2 = SinusoidalPosEmb(dim=dim_base // 2)\n",
    "#         self.proj = nn.Sequential(\n",
    "#             nn.Linear(6 * dim_base, 6 * dim_base),\n",
    "#             nn.LayerNorm(6 * dim_base),\n",
    "#             nn.GELU(),\n",
    "#             nn.Linear(6 * dim_base, dim),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x, Lmax=None):\n",
    "#         pos = x[\"pos\"] if Lmax is None else x[\"pos\"][:, :Lmax]\n",
    "#         charge = x[\"charge\"] if Lmax is None else x[\"charge\"][:, :Lmax]\n",
    "#         time = x[\"dom_time\"] if Lmax is None else x[\"dom_time\"][:, :Lmax]\n",
    "#         combined_dom_type = x[\"combined_dom_type\"] if Lmax is None else x[\"combined_dom_type\"][:, :Lmax]\n",
    "#         length = torch.log10(x[\"L0\"].to(dtype=pos.dtype))\n",
    "\n",
    "#         x = torch.cat(\n",
    "#             [\n",
    "#                 self.emb(4096 * pos).flatten(-2),\n",
    "#                 self.emb(1024 * charge),\n",
    "#                 self.emb(4096 * time),\n",
    "#                 self.emb2(length).unsqueeze(1).expand(-1, pos.shape[1], -1),\n",
    "#             ],\n",
    "#             -1,\n",
    "#         )\n",
    "#         x = self.proj(x)\n",
    "#         return x\n",
    "\n",
    "# class Extractor(nn.Module):\n",
    "#     def __init__(self, dim_base=128, dim=384):\n",
    "#         super().__init__()\n",
    "#         self.emb = SinusoidalPosEmb(dim=dim_base)\n",
    "#         self.aux_emb = nn.Embedding(2, dim_base // 2)\n",
    "#         self.emb2 = SinusoidalPosEmb(dim=dim_base // 2)\n",
    "#         self.proj = nn.Sequential(\n",
    "#             nn.Linear(6 * dim_base, 6 * dim_base),\n",
    "#             nn.LayerNorm(6 * dim_base),\n",
    "#             nn.GELU(),\n",
    "#             nn.Linear(6 * dim_base, dim),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x, Lmax=None):\n",
    "#         pos = x[\"pos\"] if Lmax is None else x[\"pos\"][:, :Lmax]\n",
    "#         charge = x[\"charge\"] if Lmax is None else x[\"charge\"][:, :Lmax]\n",
    "#         time = x[\"time\"] if Lmax is None else x[\"time\"][:, :Lmax]\n",
    "#         auxiliary = x[\"auxiliary\"] if Lmax is None else x[\"auxiliary\"][:, :Lmax]\n",
    "#         qe = x[\"qe\"] if Lmax is None else x[\"qe\"][:, :Lmax]\n",
    "#         ice_properties = (\n",
    "#             x[\"ice_properties\"] if Lmax is None else x[\"ice_properties\"][:, :Lmax]\n",
    "#         )\n",
    "#         length = torch.log10(x[\"L0\"].to(dtype=pos.dtype))\n",
    "\n",
    "#         x = torch.cat(\n",
    "#             [\n",
    "#                 self.emb(4096 * pos).flatten(-2),\n",
    "#                 self.emb(1024 * charge),\n",
    "#                 self.emb(4096 * time),\n",
    "#                 self.aux_emb(auxiliary),\n",
    "#                 self.emb2(length).unsqueeze(1).expand(-1, pos.shape[1], -1),\n",
    "#             ],\n",
    "#             -1,\n",
    "#         )\n",
    "#         x = self.proj(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "class Rel_ds(nn.Module):\n",
    "    def __init__(self, dim=32):\n",
    "        super().__init__()\n",
    "        self.emb = SinusoidalPosEmb(dim=dim)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x, Lmax=None):\n",
    "        pos = x[\"pos\"] if Lmax is None else x[\"pos\"][:, :Lmax]\n",
    "        time = x[\"time\"] if Lmax is None else x[\"time\"][:, :Lmax]\n",
    "        ds2 = (pos[:, :, None] - pos[:, None, :]).pow(2).sum(-1) - (\n",
    "            (time[:, :, None] - time[:, None, :]) * (3e4 / 500 * 3e-1)\n",
    "        ).pow(2)\n",
    "        d = torch.sign(ds2) * torch.sqrt(torch.abs(ds2))\n",
    "        emb = self.emb(1024 * d.clip(-4, 4))\n",
    "        rel_attn = self.proj(emb)\n",
    "        return rel_attn, emb\n",
    "\n",
    "\n",
    "def get_nbs(x, Lmax=None, K=8):\n",
    "    pos = x[\"pos\"] if Lmax is None else x[\"pos\"][:, :Lmax]\n",
    "    mask = x[\"mask\"][:, :Lmax]\n",
    "    B = pos.shape[0]\n",
    "\n",
    "    d = -torch.cdist(pos, pos, p=2)\n",
    "    d -= 100 * (~torch.min(mask[:, None, :], mask[:, :, None]))\n",
    "    d -= 200 * torch.eye(Lmax, dtype=pos.dtype, device=pos.device).unsqueeze(0)\n",
    "    nbs = d.topk(K - 1, dim=-1)[1]\n",
    "    nbs = torch.cat(\n",
    "        [\n",
    "            torch.arange(Lmax, dtype=nbs.dtype, device=nbs.device)\n",
    "            .unsqueeze(0)\n",
    "            .unsqueeze(-1)\n",
    "            .expand(B, -1, -1),\n",
    "            nbs,\n",
    "        ],\n",
    "        -1,\n",
    "    )\n",
    "    return nbs\n",
    "\n",
    "\n",
    "class LocalBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim=192,\n",
    "        num_heads=192 // 64,\n",
    "        mlp_ratio=4,\n",
    "        drop_path=0,\n",
    "        init_values=1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.proj_rel_bias = nn.Linear(dim // num_heads, dim // num_heads)\n",
    "        self.block = Block_rel(\n",
    "            dim=dim,\n",
    "            num_heads=num_heads,\n",
    "            mlp_ratio=mlp_ratio,\n",
    "            drop_path=drop_path,\n",
    "            init_values=init_values,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, nbs, key_padding_mask=None, rel_pos_bias=None):\n",
    "        B, Lmax, C = x.shape\n",
    "        mask = (\n",
    "            key_padding_mask\n",
    "            if not (key_padding_mask is None)\n",
    "            else torch.ones(B, Lmax, dtype=torch.bool, device=x.deice)\n",
    "        )\n",
    "\n",
    "        m = torch.gather(mask.unsqueeze(1).expand(-1, Lmax, -1), 2, nbs)\n",
    "        attn_mask = torch.zeros(m.shape, device=m.device)\n",
    "        attn_mask[~mask] = -torch.inf\n",
    "        attn_mask = attn_mask[mask]\n",
    "\n",
    "        if rel_pos_bias is not None:\n",
    "            rel_pos_bias = torch.gather(\n",
    "                rel_pos_bias,\n",
    "                2,\n",
    "                nbs.unsqueeze(-1).expand(-1, -1, -1, rel_pos_bias.shape[-1]),\n",
    "            )\n",
    "            rel_pos_bias = rel_pos_bias[mask]\n",
    "            rel_pos_bias = self.proj_rel_bias(rel_pos_bias).unsqueeze(1)\n",
    "\n",
    "        xl = torch.gather(\n",
    "            x.unsqueeze(1).expand(-1, Lmax, -1, -1),\n",
    "            2,\n",
    "            nbs.unsqueeze(-1).expand(-1, -1, -1, C),\n",
    "        )\n",
    "        xl = xl[mask]\n",
    "        # modify only the node (0th element)\n",
    "        # print(xl[:,:1].shape,rel_pos_bias.shape,attn_mask[:,:1].shape,xl.shape)\n",
    "        xl = self.block(\n",
    "            xl[:, :1],\n",
    "            rel_pos_bias=rel_pos_bias,\n",
    "            key_padding_mask=attn_mask[:, :1],\n",
    "            kv=xl,\n",
    "        )\n",
    "        x = torch.zeros(x.shape, device=x.device, dtype=xl.dtype)\n",
    "        x[mask] = xl.squeeze(1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DeepIceModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim=384,\n",
    "        dim_base=128,\n",
    "        depth=12,\n",
    "        use_checkpoint=False,\n",
    "        head_size=32,\n",
    "        depth_rel=4,\n",
    "        n_rel=1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.extractor = Extractor(dim_base, dim)\n",
    "        self.rel_pos = Rel_ds(head_size)\n",
    "        self.sandwich = nn.ModuleList(\n",
    "            [Block_rel(dim=dim, num_heads=dim // head_size) for i in range(depth_rel)]\n",
    "        )\n",
    "        self.cls_token = nn.Linear(dim, 1, bias=False)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                Block(\n",
    "                    dim=dim,\n",
    "                    num_heads=dim // head_size,\n",
    "                    mlp_ratio=4,\n",
    "                    drop_path=0.0 * (i / (depth - 1)),\n",
    "                    init_values=1,\n",
    "                )\n",
    "                for i in range(depth)\n",
    "            ]\n",
    "        )\n",
    "        self.proj_out = nn.Linear(dim, 3)\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        self.apply(self._init_weights)\n",
    "        trunc_normal_(self.cls_token.weight, std=0.02)\n",
    "        self.n_rel = n_rel\n",
    "\n",
    "    def fix_init_weight(self):\n",
    "        def rescale(param, layer_id):\n",
    "            param.div_(math.sqrt(2.0 * layer_id))\n",
    "\n",
    "        for layer_id, layer in enumerate(self.blocks):\n",
    "            rescale(layer.attn.proj.weight.data, layer_id + 1)\n",
    "            rescale(layer.mlp.fc2.weight.data, layer_id + 1)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=0.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def init_weights(self, pretrained=None):\n",
    "        def _init_weights(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                trunc_normal_(m.weight, std=0.02)\n",
    "                if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.LayerNorm):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "        self.apply(_init_weights)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {\"cls_token\"}\n",
    "\n",
    "    def forward(self, x0):\n",
    "        mask = x0[\"mask\"]\n",
    "        Lmax = mask.sum(-1).max()\n",
    "        x = self.extractor(x0, Lmax)\n",
    "        rel_pos_bias, rel_enc = self.rel_pos(x0, Lmax)\n",
    "        # nbs = get_nbs(x0, Lmax)\n",
    "        mask = mask[:, :Lmax]\n",
    "        B, _ = mask.shape\n",
    "        attn_mask = torch.zeros(mask.shape, device=mask.device)\n",
    "        attn_mask[~mask] = -torch.inf\n",
    "\n",
    "        for i, blk in enumerate(self.sandwich):\n",
    "            if isinstance(blk, LocalBlock):\n",
    "                x = blk(x, nbs, mask, rel_enc)\n",
    "            else:\n",
    "                x = blk(x, attn_mask, rel_pos_bias)\n",
    "                if i + 1 == self.n_rel:\n",
    "                    rel_pos_bias = None\n",
    "\n",
    "        mask = torch.cat(\n",
    "            [torch.ones(B, 1, dtype=mask.dtype, device=mask.device), mask], 1\n",
    "        )\n",
    "        attn_mask = torch.zeros(mask.shape, device=mask.device)\n",
    "        attn_mask[~mask] = -torch.inf\n",
    "        cls_token = self.cls_token.weight.unsqueeze(0).expand(B, -1, -1)\n",
    "        x = torch.cat([cls_token, x], 1)\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x = checkpoint.checkpoint(blk, x, None, attn_mask)\n",
    "            else:\n",
    "                x = blk(x, None, attn_mask)\n",
    "\n",
    "        x = self.proj_out(x[:, 0])  # cls token\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=126'>127</a>\u001b[0m model \u001b[39m=\u001b[39m DeepIceModel(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=127'>128</a>\u001b[0m         dim\u001b[39m=\u001b[39m\u001b[39m384\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=128'>129</a>\u001b[0m         dim_base\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, \u001b[39m#128\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=133'>134</a>\u001b[0m         n_rel\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=134'>135</a>\u001b[0m         )\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=137'>138</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (features, truth) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dl):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=138'>139</a>\u001b[0m     \n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=139'>140</a>\u001b[0m     \u001b[39m# Forward pass: Compute predicted y by passing x to the model\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=140'>141</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m model(features)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=142'>143</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatch \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=143'>144</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFeatures:\u001b[39m\u001b[39m\"\u001b[39m, features[\u001b[39m'\u001b[39m\u001b[39mcharge\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/icet2/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb Cell 11\u001b[0m line \u001b[0;36m7\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=699'>700</a>\u001b[0m mask \u001b[39m=\u001b[39m x0[\u001b[39m\"\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=700'>701</a>\u001b[0m Lmax \u001b[39m=\u001b[39m mask\u001b[39m.\u001b[39msum(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mmax()\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=701'>702</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextractor(x0, Lmax)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=702'>703</a>\u001b[0m rel_pos_bias, rel_enc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrel_pos(x0, Lmax)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=703'>704</a>\u001b[0m \u001b[39m# nbs = get_nbs(x0, Lmax)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/icet2/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb Cell 11\u001b[0m line \u001b[0;36m4\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=437'>438</a>\u001b[0m pos \u001b[39m=\u001b[39m x[\u001b[39m\"\u001b[39m\u001b[39mpos\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m Lmax \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m x[\u001b[39m\"\u001b[39m\u001b[39mpos\u001b[39m\u001b[39m\"\u001b[39m][:, :Lmax]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=438'>439</a>\u001b[0m charge \u001b[39m=\u001b[39m x[\u001b[39m\"\u001b[39m\u001b[39mcharge\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m Lmax \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m x[\u001b[39m\"\u001b[39m\u001b[39mcharge\u001b[39m\u001b[39m\"\u001b[39m][:, :Lmax]\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=439'>440</a>\u001b[0m time \u001b[39m=\u001b[39m x[\u001b[39m\"\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m Lmax \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m x[\u001b[39m\"\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m\"\u001b[39;49m][:, :Lmax]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=441'>442</a>\u001b[0m combined_dom_type \u001b[39m=\u001b[39m x[\u001b[39m\"\u001b[39m\u001b[39mcombined_dom_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m Lmax \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m x[\u001b[39m\"\u001b[39m\u001b[39mcombined_dom_type\u001b[39m\u001b[39m\"\u001b[39m][:, :Lmax]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226865705f475055227d/groups/icecube/moust/work/IceCubeEncoderTransformer/notebooks/kaggle_2nd_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=442'>443</a>\u001b[0m length \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlog10(x[\u001b[39m\"\u001b[39m\u001b[39mL0\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mpos\u001b[39m.\u001b[39mdtype))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time'"
     ]
    }
   ],
   "source": [
    "chunk_csv_train = [\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_1.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_2.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_3.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_4.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_5.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_6.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/train/output_7.csv\",\n",
    "]\n",
    "chunk_csv_test = [\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_1.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_2.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_3.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_4.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_5.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_6.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/test/output_7.csv\",\n",
    "]\n",
    "chunk_csv_val = [\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_1.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_2.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_3.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_4.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_5.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_6.csv\",\n",
    "  \"/groups/icecube/moust/storage/cached_event_no/upgrade_numu/val/output_7.csv\",\n",
    "]\n",
    "\n",
    "batch_sizes = [512, 256, 128, 64, 32, 16, 8]\n",
    "truth_table = \"truth\"\n",
    "db_path = \"/groups/icecube/petersen/GraphNetDatabaseRepository/Upgrade_Data/sqlite3/dev_step4_upgrade_028_with_noise_dynedge_pulsemap_v3_merger_aftercrash.db\"\n",
    "pulsemap = \"SplitInIcePulses_dynedge_v2_Pulses\"\n",
    "input_cols =  [\"dom_x\", \"dom_y\", \"dom_z\", \"dom_time\", \"charge\"]\n",
    "target_cols = \"inelasticity\"\n",
    "\n",
    "# class ChunkDataset(Dataset):\n",
    "#     \"\"\"\n",
    "#     PyTorch dataset for loading chunked data from an SQLite database.\n",
    "#     This dataset retrieves pulsemap and truth data for each event from the database.\n",
    "\n",
    "#     Args:\n",
    "#         db_filename (str): Filename of the SQLite database.\n",
    "#         csv_filenames (list of str): List of CSV filenames containing event numbers.\n",
    "#         pulsemap_table (str): Name of the table containing pulsemap data.\n",
    "#         truth_table (str): Name of the table containing truth data.\n",
    "#         truth_variable (str): Name of the variable to query from the truth table.\n",
    "#         feature_variables (list of str): List of variable names to query from the pulsemap table.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         db_path: str,\n",
    "#         chunk_csvs: List[str],\n",
    "#         pulsemap: str,\n",
    "#         truth_table: str,\n",
    "#         target_cols: str,\n",
    "#         input_cols: List[str]\n",
    "#     ) -> None:\n",
    "#         self.conn = sqlite3.connect(db_path)  # Connect to the SQLite database\n",
    "#         self.c = self.conn.cursor()\n",
    "#         self.event_nos = []\n",
    "#         for csv_filename in chunk_csvs:\n",
    "#             df = pd.read_csv(csv_filename)\n",
    "#             self.event_nos.extend(df['event_no'].tolist())  # Collect event numbers from CSV files\n",
    "#         self.pulsemap = pulsemap  # Name of the table containing pulsemap data\n",
    "#         self.truth_table = truth_table  # Name of the table containing truth data\n",
    "#         self.target_cols = target_cols  # Name of the variable to query from the truth table\n",
    "#         self.input_cols = input_cols  # List of variable names to query from the pulsemap table\n",
    "\n",
    "\n",
    "#     def __len__(self) -> int:\n",
    "#         return len(self.event_nos)\n",
    "\n",
    "#     def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "#         # print(idx)\n",
    "#         event_no = idx # self.event_nos[idx]\n",
    "#         # print(event_no)\n",
    "#         # Query the truth variable for the given event number\n",
    "#         self.c.execute(f\"SELECT {self.target_cols} FROM {self.truth_table} WHERE event_no = ?\", (event_no,))\n",
    "#         truth_value = self.c.fetchone()[0]\n",
    "#         input_query = ', '.join(self.input_cols)\n",
    "#         # Query the feature variables from the pulsemap table for the given event number\n",
    "#         self.c.execute(f\"SELECT {input_query} FROM {self.pulsemap} WHERE event_no = ?\", (event_no,))\n",
    "#         pulsemap_data = self.c.fetchall()\n",
    "#         return torch.tensor(truth_value, dtype=torch.float32), torch.tensor(pulsemap_data, dtype=torch.float32)\n",
    "    \n",
    "#     def close_connection(self) -> None:\n",
    "#         self.conn.close()\n",
    "\n",
    "\n",
    "# def get_nbs(x, Lmax=None, K=8):\n",
    "#     pos = x[\"pos\"] if Lmax is None else x[\"pos\"][:, :Lmax]\n",
    "#     mask = x[\"mask\"][:, :Lmax]\n",
    "#     B = pos.shape[0]\n",
    "\n",
    "#     d = -torch.cdist(pos, pos, p=2)\n",
    "#     d -= 100 * (~torch.min(mask[:, None, :], mask[:, :, None]))\n",
    "#     d -= 200 * torch.eye(Lmax, dtype=pos.dtype, device=pos.device).unsqueeze(0)\n",
    "#     nbs = d.topk(K - 1, dim=-1)[1]\n",
    "#     nbs = torch.cat(\n",
    "#         [\n",
    "#             torch.arange(Lmax, dtype=nbs.dtype, device=nbs.device)\n",
    "#             .unsqueeze(0)\n",
    "#             .unsqueeze(-1)\n",
    "#             .expand(B, -1, -1),\n",
    "#             nbs,\n",
    "#         ],\n",
    "#         -1,\n",
    "#     )\n",
    "#     return nbs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print()\n",
    "# print(\"Model test\")\n",
    "# print()\n",
    "model = DeepIceModel(\n",
    "        dim=384,\n",
    "        dim_base=128, #128\n",
    "        depth=12,\n",
    "        use_checkpoint=False,\n",
    "        head_size=32,\n",
    "        depth_rel=4,\n",
    "        n_rel=1,\n",
    "        )\n",
    "\n",
    "\n",
    "for i, (features, truth) in enumerate(dl):\n",
    "    \n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(features)\n",
    "\n",
    "    print(f\"Batch {i + 1}\")\n",
    "    print(\"Features:\", features['charge'].shape)\n",
    "    print(\"Truth:\", truth.shape)\n",
    "    print(\"Predicted:\", y_pred.shape)\n",
    "\n",
    "    if i == 60:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols =  [\"dom_x\", \"dom_y\", \"dom_z\", \"dom_time\", \"charge\", \"rde\", \"dom_type\"]\n",
    "combine_dom_types_and_rde = [\"rde\", \"dom_type\"]\n",
    "posistion_cols = [\"dom_x\", \"dom_y\", \"dom_z\"]\n",
    "list1 = [1, 2, 3, 4, 5, 6, 7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ChunkDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch dataset for loading chunked data from an SQLite database.\n",
    "    This dataset retrieves pulsemap and truth data for each event from the database.\n",
    "\n",
    "    Args:\n",
    "        db_filename (str): Filename of the SQLite database.\n",
    "        csv_filenames (list of str): List of CSV filenames containing event numbers.\n",
    "        pulsemap_table (str): Name of the table containing pulsemap data.\n",
    "        truth_table (str): Name of the table containing truth data.\n",
    "        truth_variable (str): Name of the variable to query from the truth table.\n",
    "        feature_variables (list of str): List of variable names to query from the pulsemap table.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        db_path: str,\n",
    "        chunk_csvs: List[str],\n",
    "        pulsemap: str,\n",
    "        truth_table: str,\n",
    "        target_cols: str,\n",
    "        input_cols: List[str]\n",
    "    ) -> None:\n",
    "        self.conn = sqlite3.connect(db_path)  # Connect to the SQLite database\n",
    "        self.c = self.conn.cursor()\n",
    "        self.event_nos = []\n",
    "        for csv_filename in chunk_csvs:\n",
    "            df = pd.read_csv(csv_filename)\n",
    "            self.event_nos.extend(df['event_no'].tolist())  # Collect event numbers from CSV files\n",
    "        self.pulsemap = pulsemap  # Name of the table containing pulsemap data\n",
    "        self.truth_table = truth_table  # Name of the table containing truth data\n",
    "        self.target_cols = target_cols  # Name of the variable to query from the truth table\n",
    "        self.input_cols = input_cols  # List of variable names to query from the pulsemap table\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.event_nos)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        event_no = idx # self.event_nos[idx]\n",
    "\n",
    "        # Query the truth variable for the given event number\n",
    "        self.c.execute(f\"SELECT {self.target_cols} FROM {self.truth_table} WHERE event_no = ?\", (event_no,))\n",
    "        truth_value = self.c.fetchone()[0]\n",
    "        \n",
    "\n",
    "        pos_cols = ['dom_x', 'dom_y', 'dom_z']\n",
    "\n",
    "        rde_index = self.input_cols.index('rde')\n",
    "        dom_type_index = self.input_cols.index('dom_type')\n",
    "        pos_indices = [self.input_cols.index(col) for col in pos_cols]\n",
    "        rest_indices = [i for i in range(len(self.input_cols)) if i not in [rde_index, dom_type_index] + pos_indices]\n",
    "\n",
    "        input_query = ', '.join(self.input_cols)\n",
    "        # print(input_query)\n",
    "        # Query the feature variables from the pulsemap table for the given event number\n",
    "        self.c.execute(f\"SELECT {input_query} FROM {self.pulsemap} WHERE event_no = ?\", (event_no,))\n",
    "        pulsemap_data_rows = self.c.fetchall()\n",
    "    \n",
    "        # Convert pulsemap_data_rows into a dictionary of tensors\n",
    "        \n",
    "        pulsemap_data = {self.input_cols[i]: torch.tensor( [row[i] for row in pulsemap_data_rows], dtype=torch.float32)\n",
    "                        for i in rest_indices}\n",
    "        \n",
    "        # Get the necessary data for combined_dom_type and pos\n",
    "        dom_type_data = [row[dom_type_index] for row in pulsemap_data_rows] #[row[i] for row in pulsemap_data_rows for i in combined_dom_type_indices]\n",
    "        rde_data = [row[rde_index] for row in pulsemap_data_rows]  #[row[i] for row in pulsemap_data_rows for i in combined_dom_type_indices]\n",
    "        pos_data = [[row[i] for row in pulsemap_data_rows] for i in pos_indices]\n",
    "\n",
    "        pulsemap_data[\"combined_dom_type\"] = combine_dom_types_and_rde(torch.tensor(dom_type_data, dtype=torch.float32),\n",
    "                                                                    torch.tensor(rde_data, dtype=torch.float32))\n",
    "        pulsemap_data[\"pos\"] = torch.stack([torch.tensor(col_data, dtype=torch.float32) for col_data in pos_data], dim=1)\n",
    "        pulsemap_data[\"L0\"] = torch.tensor(len(pulsemap_data_rows), dtype=torch.float32)\n",
    "\n",
    "        return pulsemap_data, torch.tensor(truth_value, dtype=torch.float32)\n",
    "    \n",
    "\n",
    "    # def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    #     # print(idx)\n",
    "    #     event_no = idx # self.event_nos[idx]\n",
    "    #     # print(event_no)\n",
    "    #     # Query the truth variable for the given event number\n",
    "    #     self.c.execute(f\"SELECT {self.target_cols} FROM {self.truth_table} WHERE event_no = ?\", (event_no,))\n",
    "    #     truth_value = self.c.fetchone()[0]\n",
    "    #     input_query = ', '.join(self.input_cols)\n",
    "    #     # Query the feature variables from the pulsemap table for the given event number\n",
    "    #     self.c.execute(f\"SELECT {input_query} FROM {self.pulsemap} WHERE event_no = ?\", (event_no,))\n",
    "    #     pulsemap_data = self.c.fetchall()\n",
    "    #     # Convert pulsemap_data into a dictionary of tensors\n",
    "    #     pulsemap_data = {col: torch.tensor([row[i] for row in pulsemap_data], dtype=torch.float32)\n",
    "    #                      for i, col in enumerate(self.input_cols)}\n",
    "    #     pulsemap_data[\"combined_dom_type\"] = combine_dom_types_and_rde(pulsemap_data[\"dom_type\"], pulsemap_data[\"rde\"])\n",
    "    #     pulsemap_data[\"pos\"] = torch.stack([pulsemap_data[\"dom_x\"], pulsemap_data[\"dom_y\"], pulsemap_data[\"dom_z\"]], dim=1) \n",
    "    #     del pulsemap_data['dom_x']\n",
    "    #     del pulsemap_data['dom_y']\n",
    "    #     del pulsemap_data['dom_z']\n",
    "    #     del pulsemap_data['dom_type']\n",
    "    #     del pulsemap_data['rde']\n",
    "    #     return pulsemap_data, torch.tensor(truth_value, dtype=torch.float32)\n",
    "    # {'truth': torch.tensor(truth_value, dtype=torch.float32), 'pulsemap': pulsemap_data}\n",
    "        \n",
    "    def close_connection(self) -> None:\n",
    "        self.conn.close()\n",
    "\n",
    "def combine_dom_types_and_rde( dom_type, rde):\n",
    "        # pDom dom with low efficiency\n",
    "        pdom_low_qe = ((dom_type == 20) & (rde == 1)).float().unsqueeze(-1)\n",
    "        # pDOM dom with high efficiency\n",
    "        pdom_high_qe = ((dom_type == 20) & (rde == 1.35)).float().unsqueeze(-1)\n",
    "        # pDOM upgrade == 110\n",
    "        pdom_upgrade = (dom_type == 110).float().unsqueeze(-1)\n",
    "        # D-EGG == 120\n",
    "        d_egg = (dom_type == 120).float().unsqueeze(-1)\n",
    "        # mDOM == 130\n",
    "        mdom = (dom_type == 130).float().unsqueeze(-1)\n",
    "\n",
    "        return torch.cat([pdom_low_qe, pdom_high_qe, pdom_upgrade, d_egg, mdom], dim=-1)\n",
    "\n",
    "\n",
    "class ChunkSampler(Sampler):\n",
    "    \"\"\"\n",
    "    PyTorch sampler for creating chunks from event numbers.\n",
    "\n",
    "    Args:\n",
    "        csv_filenames (List[str]): List of CSV filenames containing event numbers.\n",
    "        batch_sizes (List[int]): List of batch sizes for each CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        chunk_csvs: List[str], \n",
    "        batch_sizes: List[int]\n",
    "    ) -> None:\n",
    "        self.event_nos = []\n",
    "        for csv_filename, batch_size in zip(chunk_csvs, batch_sizes):\n",
    "            event_nos = pd.read_csv(csv_filename)['event_no'].tolist()\n",
    "            self.event_nos.extend([event_nos[i:i + batch_size] for i in range(0, len(event_nos), batch_size)])\n",
    "\n",
    "    def __iter__(self) -> Iterator:\n",
    "        return iter(self.event_nos)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.event_nos)\n",
    "    \n",
    "# def collate_fn(data: List[Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]]]) -> Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]]:\n",
    "#     truths = [item['truth'] for item in data]\n",
    "#     pulsemap_data = [item['pulsemap'] for item in data]\n",
    "#     # Pad each feature separately\n",
    "#     max_length = max(len(item['pos']) for item in pulsemap_data)\n",
    "#     for item in pulsemap_data:\n",
    "#         for feature, tensor in item.items():\n",
    "#             pad_length = max_length - len(tensor)\n",
    "#             item[feature] = F.pad(tensor, (0, pad_length))\n",
    "#     # Create the mask\n",
    "#     mask = torch.stack([torch.cat([torch.ones(len(item['pos']), dtype=torch.bool),\n",
    "#                                    torch.zeros(max_length - len(item['pos']), dtype=torch.bool)]) for item in pulsemap_data])\n",
    "#     return {'truth': torch.stack(truths), 'pulsemap': pulsemap_data, 'mask': mask}\n",
    "def collate_fn(data: List[Tuple[torch.Tensor, torch.Tensor]]) -> Dict[str, torch.Tensor]:\n",
    "    truths, pulsemap_data = zip(*data)\n",
    "\n",
    "    for item in pulsemap_data:\n",
    "        item['pos'] = torch.stack([item['dom_x'], item['dom_y'], item['dom_z']], dim=-1)\n",
    "        item['dom_type_rde'] = combine_dom_types_and_efficiency(item['dom_type'], item['rde'])\n",
    "\n",
    "    max_length = max(len(item['pos']) for item in pulsemap_data)\n",
    "\n",
    "    pos_data = torch.zeros(len(pulsemap_data), max_length, 3)\n",
    "    charge_data = torch.zeros(len(pulsemap_data), max_length)\n",
    "    time_data = torch.zeros(len(pulsemap_data), max_length)\n",
    "    dom_type_rde_data = torch.zeros(len(pulsemap_data), max_length, 5)\n",
    "    mask = torch.zeros(len(pulsemap_data), max_length, dtype=torch.bool)\n",
    "\n",
    "    for i, item in enumerate(pulsemap_data):\n",
    "        pos_data[i, :len(item['pos'])] = item['pos']\n",
    "        charge_data[i, :len(item['charge'])] = item['charge']\n",
    "        time_data[i, :len(item['time'])] = item['time']\n",
    "        dom_type_rde_data[i, :len(item['dom_type_rde'])] = item['dom_type_rde']\n",
    "        mask[i, :len(item['pos'])] = 1\n",
    "\n",
    "    return {\n",
    "        'pulsemap': {\n",
    "            'pos': pos_data,\n",
    "            'charge': charge_data,\n",
    "            'time': time_data,\n",
    "            'dom_type_rde': dom_type_rde_data\n",
    "        },\n",
    "        'mask': mask,\n",
    "        'truth': torch.stack(truths)\n",
    "    }\n",
    "\n",
    "# def combine_dom_types_and_efficiency(dom_type, rde):\n",
    "#     print(f\"Dom_type tensor: {dom_type}, RDE tensor: {rde}\") \n",
    "#     # Normal dom with low efficiency\n",
    "#     type1 = ((dom_type == 20) & (rde == 0)).float().unsqueeze(-1)\n",
    "#     # Normal dom with high efficiency\n",
    "#     type2 = ((dom_type == 20) & (rde == 1)).float().unsqueeze(-1)\n",
    "#     # dom_type == 110\n",
    "#     type3 = (dom_type == 110).float().unsqueeze(-1)\n",
    "#     # dom_type == 120\n",
    "#     type4 = (dom_type == 120).float().unsqueeze(-1)\n",
    "#     # dom_type == 130\n",
    "#     type5 = (dom_type == 130).float().unsqueeze(-1)\n",
    "\n",
    "#     return torch.cat([type1, type2, type3, type4, type5], dim=-1)\n",
    "\n",
    "input_cols =  [\"dom_x\", \"dom_y\", \"dom_z\", \"dom_time\", \"charge\", \"rde\", \"dom_type\"]\n",
    "\n",
    "dataset = ChunkDataset(\n",
    "    db_path=db_path, \n",
    "    chunk_csvs=chunk_csv_train, \n",
    "    pulsemap=pulsemap, \n",
    "    truth_table=truth_table, \n",
    "    target_cols=target_cols, \n",
    "    input_cols=input_cols\n",
    "    )\n",
    "\n",
    "# dl = DataLoader(\n",
    "#     dataset=dataset,\n",
    "#     collate_fn=collate_fn,\n",
    "#     batch_sampler=ChunkSampler(chunk_csv_train, batch_sizes),\n",
    "#     num_workers=12,\n",
    "# )\n",
    "# dl = DataLoader(\n",
    "#     dataset=dataset,\n",
    "#     collate_fn=collate_fn,\n",
    "#     batch_sampler=ChunkSampler(chunk_csv_train, batch_sizes),\n",
    "#     num_workers=12,\n",
    "# )\n",
    "\n",
    "# for i, (features, truth) in enumerate(dataset):\n",
    "#     print(i)\n",
    "#     print(features, truth)\n",
    "#     print(features['dom_x'])\n",
    "#     if i >= 10:\n",
    "#         break\n",
    "\n",
    "# # Iterate over the first 10 batches\n",
    "# for i, batch in enumerate(dl):\n",
    "#     if i >= 10:\n",
    "#         break\n",
    "#     features = batch['pulsemap']\n",
    "#     mask = batch['mask']\n",
    "#     truth = batch['truth']\n",
    "#     print(i, features, mask, truth)\n",
    "\n",
    "features, truth = dataset[6]\n",
    "# print(features, truth)\n",
    "print(features['L0'].max().item() if features['L0'] is not None else max(len(item) for item in x['pos']))\n",
    "# print(features['pos'].shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 100, 384])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Instantiate the extractor\n",
    "extractor = Extractor()\n",
    "\n",
    "# Create a batch of data\n",
    "batch_size = 16\n",
    "max_length = 100\n",
    "batch = {\n",
    "    'pulsemap': {\n",
    "        'pos': torch.randn(batch_size, max_length, 3),\n",
    "        'charge': torch.randn(batch_size, max_length),\n",
    "        'time': torch.randn(batch_size, max_length),\n",
    "        'dom_type_rde': torch.randint(0, 2, (batch_size, max_length, 5)).float()\n",
    "    },\n",
    "    'mask': torch.ones(batch_size, max_length, dtype=torch.bool),\n",
    "    'L0': torch.tensor([max_length]*batch_size),  # adding the sequence length\n",
    "    'truth': torch.randn(batch_size, 3)\n",
    "}\n",
    "\n",
    "# Feed the batch to the extractor\n",
    "output = extractor(batch['pulsemap'], batch['L0'])\n",
    "\n",
    "# Print the shape of the output\n",
    "print(\"Output shape:\", output.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 10, 384])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "max_length = 10\n",
    "batch = {\n",
    "    'pulsemap': {\n",
    "        'pos': torch.randn(batch_size, max_length, 3),\n",
    "        'charge': torch.randn(batch_size, max_length),\n",
    "        'time': torch.randn(batch_size, max_length),\n",
    "        'dom_type_rde': torch.randn(batch_size, max_length, 5)\n",
    "    },\n",
    "    'L0': torch.tensor([max_length] * batch_size),\n",
    "    'truth': torch.randn(batch_size, 3)\n",
    "}\n",
    "\n",
    "# Create the extractor\n",
    "extractor = Extractor()\n",
    "\n",
    "# Feed the batch to the extractor\n",
    "output = extractor(batch['pulsemap'], batch['L0'])\n",
    "\n",
    "# Print the shape of the output\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icet2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
